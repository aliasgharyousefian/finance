{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[{"file_id":"1OWoAM0X8c22UrNrQsNQNxjA6BmUANz83","timestamp":1602868462673},{"file_id":"1VFI7jNkQ6L6v-hjjjdKNXs2syU4DOMn6","timestamp":1602272719547},{"file_id":"1MjJqNB47XoD0bAjYI9AaIwgetTaVmj1p","timestamp":1602253712448},{"file_id":"12-0LyMaLOob79jCa8IlFH_XNmfjtBwtH","timestamp":1602051192385}],"collapsed_sections":["nKPoCKpAfN4S","rdSIkjfcaIJB","-RrCNJD7Z-aJ","PFGckui2Vsli","-SFXtsuwovMn"]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3qsisLNZf6zf"},"source":["# **google drive.mount**"]},{"cell_type":"code","metadata":{"id":"0lpfffro4ZWq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654846564163,"user_tz":-270,"elapsed":144111,"user":{"displayName":"Ali Asghar Yousefian","userId":"17320255365069876391"}},"outputId":"f1e831e8-13d5-4076-8687-cb183d1d8018"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"nKPoCKpAfN4S"},"source":["# **import  ta-lib and ...**"]},{"cell_type":"code","metadata":{"id":"mUeU_EhspQp1"},"source":["!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n","!tar -xzvf ta-lib-0.4.0-src.tar.gz\n","%cd ta-lib\n","!./configure --prefix=/usr\n","!make\n","!make install\n","!pip install Ta-Lib\n","\n","import talib"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"109W5JOzff2e"},"source":["# **import** **LIB**..."]},{"cell_type":"code","metadata":{"id":"-19HwvVJufrT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654846707069,"user_tz":-270,"elapsed":7450,"user":{"displayName":"Ali Asghar Yousefian","userId":"17320255365069876391"}},"outputId":"c91c437f-6525-4070-83c3-e6e9bdca82d2"},"source":["from bs4 import BeautifulSoup\n","import requests\n","import pandas as pd\n","import csv\n","import numpy as np\n","from scipy import stats\n","from pandas import DataFrame\n","import xlrd \n","from datetime import datetime\n","import matplotlib.pyplot as plt\n","import datetime\n","import random\n","import math\n","import sklearn\n","import sklearn.preprocessing\n","from sklearn import preprocessing\n","from collections import deque\n","import datetime\n","import os\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","#!pip install tehran_stocks\n","#from tehran_stocks import get_all_price, Stocks, update_group, db\n","#!pip install tpot\n","!pip install evaluation\n","\n","from google.colab import files\n","import time\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, LSTM, LSTM, BatchNormalization\n","from keras import callbacks\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","import pandas as pd\n","import random\n","import matplotlib.pyplot\n","%matplotlib inline \n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting evaluation\n","  Downloading evaluation-0.0.2.tar.gz (2.1 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from evaluation) (1.21.6)\n","Collecting glog\n","  Downloading glog-0.3.1-py2.py3-none-any.whl (7.8 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from glog->evaluation) (1.15.0)\n","Collecting python-gflags>=3.1\n","  Downloading python-gflags-3.1.2.tar.gz (52 kB)\n","\u001b[K     |████████████████████████████████| 52 kB 921 kB/s \n","\u001b[?25hBuilding wheels for collected packages: evaluation, python-gflags\n","  Building wheel for evaluation (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for evaluation: filename=evaluation-0.0.2-py3-none-any.whl size=2479 sha256=bbfcc5fbd4ab8dabc0a51b5679cc7493c407e7160d9a97330fbe9ef005a062e5\n","  Stored in directory: /root/.cache/pip/wheels/18/75/b8/63929bfb42b59346c83a70f51ef709888e344cb34172930ef2\n","  Building wheel for python-gflags (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-gflags: filename=python_gflags-3.1.2-py3-none-any.whl size=57386 sha256=b82ebb32f7f5b18bbc18ac4991c37e3cdc2255510e393c7caa79e69aa957d9af\n","  Stored in directory: /root/.cache/pip/wheels/df/27/8a/e46bf628958f821f7d2092f276f5a81e184bcf1a1ccdeecd95\n","Successfully built evaluation python-gflags\n","Installing collected packages: python-gflags, glog, evaluation\n","Successfully installed evaluation-0.0.2 glog-0.3.1 python-gflags-3.1.2\n"]}]},{"cell_type":"markdown","metadata":{"id":"rdSIkjfcaIJB"},"source":["# **def dollar**"]},{"cell_type":"code","metadata":{"id":"7VRoEb3oufrY"},"source":["def dollar():\n","  global dolar\n","  dollar_his='/content/drive/My Drive/Colab Notebooks/total data/dollar data.xlsx' \n","  location_2=dollar_his\n","\n","  dataset_dollar= pd.read_excel(location_2, usecols=[0,1])\n","  dataset_dollar=dataset_dollar.dropna()\n","  dataset_dollar=dataset_dollar[['<DTYYYYMMDD>','<Close>']]\n","  dataset_dollar['<Close>'].values.astype(int)\n","  dataset_dollar['<DTYYYYMMDD>'] = pd.to_datetime(dataset_dollar['<DTYYYYMMDD>'],format='%Y%m%d').dt.strftime(\"%Y%m%d\"); dataset_dollar\n","  \n","  #url_dollar='https://www.tgju.org/chart-summary-ajax/price_dollar_rl?_=1580199658457'\n","  \n","  url_dollar='https://api.tgju.online/v1/market/indicator/summary-table-data/price_dollar_rl?'\n","  page = requests.get(url_dollar)\n","  soup=BeautifulSoup((page.text),\"lxml\")\n","  t=soup.find('span')\n","  output = []\n","  file_input = (t.text).split('\"')\n","  for row in file_input:\n","      output.append(row.split('\",'))\n","  \n","  tarikh_sh=[]\n","  tarikh_m=[]\n","  gheymat=[]\n","  a=0                        \n","  while (16*a)<=(len(output)-20) :\n","      tarikh_sh.append(output[16*a + 6])\n","      tarikh_m.append(output[16*a + 4])\n","      gheymat.append(output[16*a+8])\n","      a=a+1\n","\n","  \n","  df_1 = pd.DataFrame(np.array(tarikh_sh))\n","  df_2 = pd.DataFrame(np.array(tarikh_m))\n","  df_3 = pd.DataFrame(np.array(gheymat)) \n","  \n","  df_1['tarikh_sh'] = pd.DataFrame(np.array(tarikh_sh))\n","  df_2['<DTYYYYMMDD>'] = pd.DataFrame(np.array(tarikh_m))\n","  df_3['<Close>'] = pd.DataFrame(np.array(gheymat)) \n","  \n","  dollar_online = pd.concat([df_2['<DTYYYYMMDD>'],df_3['<Close>']], axis=1)\n","  dollar_online['<DTYYYYMMDD>'] = pd.to_datetime(dollar_online['<DTYYYYMMDD>'],format='%Y\\/%m\\/%d').dt.strftime(\"%Y%m%d\"); dollar_online\n","  \n","  df=pd.concat([dataset_dollar,dollar_online], axis=0 , join='outer', ignore_index=False, keys=None,levels=None, names=None, verify_integrity=False, copy=True,)\n","  df_new=df.astype(str).sort_values(by=['<DTYYYYMMDD>'])\n","  df_new=df_new.drop_duplicates(subset='<DTYYYYMMDD>', keep='first')\n","  \n","  f=df_new\n","  f['<DTYYYYMMDD>'] = pd.to_datetime(f['<DTYYYYMMDD>'])\n","  f.set_index('<DTYYYYMMDD>', inplace=True)\n","  f.sort_index(inplace=True)\n","      \n","  dolar = f.asfreq('d',how={'<Close>': 'mean'}).ffill().rename(columns={'<Close>': 'dollar'})  \n","  dolar['dollar'] = dolar['dollar'].str.replace(',','').astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-RrCNJD7Z-aJ"},"source":["# **def sekke**"]},{"cell_type":"code","metadata":{"id":"PfqHGZXGhV_s"},"source":["def sekke():\n","  global seke\n","  his='/content/drive/My Drive/Colab Notebooks/total data/sekeJadid.xlsx' \n","  location_2=his\n","  dataset= pd.read_excel(location_2, usecols=[0,1])\n","  dataset=dataset.dropna()\n","  dataset=dataset[['<DTYYYYMMDD>','<Close>']]\n","  dataset['<Close>'].values.astype(int)\n","  dataset['<DTYYYYMMDD>'] = pd.to_datetime(dataset['<DTYYYYMMDD>'],format='%Y%m%d').dt.strftime(\"%Y%m%d\"); dataset\n","  \n","  url='https://api.tgju.online/v1/market/indicator/summary-table-data/sekeb?'\n","  page = requests.get(url)\n","  soup=BeautifulSoup((page.text),\"lxml\")\n","  t=soup.find('span')\n","  output = []\n","  file_input = (t.text).split('\"')\n","  for row in file_input:\n","    output.append(row.split('\",'))\n","\n","  \n","  tarikh_sh=[]\n","  tarikh_m=[]\n","  gheymat=[]\n","  a=0                        \n","\n","  while (16*a)<=(len(output)-20) :\n","      tarikh_sh.append(output[16*a + 6])\n","      tarikh_m.append(output[16*a + 4])\n","      gheymat.append(output[16*a+8])\n","      a=a+1\n","  df_1 = pd.DataFrame(np.array(tarikh_sh))\n","  df_2 = pd.DataFrame(np.array(tarikh_m))\n","  df_3 = pd.DataFrame(np.array(gheymat)) \n","  \n","  df_1['tarikh_sh'] = pd.DataFrame(np.array(tarikh_sh))\n","  df_2['<DTYYYYMMDD>'] = pd.DataFrame(np.array(tarikh_m))\n","  df_3['<Close>'] = pd.DataFrame(np.array(gheymat)) \n","  \n","  online = pd.concat([df_2['<DTYYYYMMDD>'],df_3['<Close>']], axis=1)\n","  online['<DTYYYYMMDD>'] = pd.to_datetime(online['<DTYYYYMMDD>'],format='%Y\\/%m\\/%d').dt.strftime(\"%Y%m%d\"); online\n","  \n","  df=pd.concat([dataset,online], axis=0 , join='outer', ignore_index=False, keys=None,levels=None, names=None, verify_integrity=False, copy=True,)\n","  df_new=df.astype(str).sort_values(by=['<DTYYYYMMDD>'])\n","  df_new=df_new.drop_duplicates(subset='<DTYYYYMMDD>', keep='first')\n","  \n","  f=df_new\n","  f['<DTYYYYMMDD>'] = pd.to_datetime(f['<DTYYYYMMDD>'])\n","  f.set_index('<DTYYYYMMDD>', inplace=True)\n","  f.sort_index(inplace=True)    \n","  seke = f.asfreq('d',how={'<Close>': 'mean'}).ffill().rename(columns={'<Close>': 'seke'})\n","  seke['seke'] = seke['seke'].str.replace(',','').astype(int)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PFGckui2Vsli"},"source":["## **def shakhes kol**"]},{"cell_type":"code","metadata":{"id":"4x1-O6p2ufrg"},"source":["def shakhes():\n","    global shakhes_kol\n"," \n","    a=str('شاخص كل6')\n","\n","    loc='/content/drive/My Drive/Colab Notebooks/stock/'+'{}'.format(a)+'.xls' \n","    loc_2=loc\n","\n","    cols_X_1 = [1,5,6,7,8] #open/high/low/close\n","    dataset_sh= pd.read_excel(loc_2, usecols=cols_X_1)\n","    dataset_sh=dataset_sh.dropna()\n","    dataset_sh=dataset_sh[['<DTYYYYMMDD>','<CLOSE>','<VOL>','<VALUE>','<NUM>']]\n","    \n","    dataset_sh['<DTYYYYMMDD>'] = pd.to_datetime(dataset_sh['<DTYYYYMMDD>'], format='%Y%m%d').dt.strftime(\"%Y-%m-%d\"); dataset_sh\n","    \n","    dataset_sh['<DTYYYYMMDD>'] = pd.to_datetime(dataset_sh['<DTYYYYMMDD>'])\n","    dataset_sh.set_index('<DTYYYYMMDD>', inplace=True)\n","    dataset_sh.sort_index(inplace=True)\n","    dataset_sh= dataset_sh[(np.abs(stats.zscore(dataset_sh)) < 10).all(axis=1)]\n"," \n","    #dataset_sh['5/30day MA V-SHAKHES'] = ((dataset_sh['<VOL>'].shift(1).rolling(window = 5).mean()-dataset_sh['<VOL>']\n","     #       .shift(1).rolling(window = 30).mean())/dataset_sh['<VOL>'].shift(1).rolling(window = 30).mean())\n","    #dataset_sh['5/30day MA Value-SHAKHES'] = ((dataset_sh['<VALUE>'].shift(1).rolling(window = 5).mean()-dataset_sh['<VALUE>']\n","               # .shift(1).rolling(window = 30).mean())/dataset_sh['<VALUE>'].shift(1).rolling(window = 30).mean())\n","    #dataset_sh['<VALUE> sum shakhes']=dataset_sh['<VALUE>'].cumsum()\n","    #dataset_sh['5/(30+90+180+365)day MA Value-SHAKHES']=((dataset_sh['<VALUE>'].shift(1).rolling(window = 5).mean()-dataset_sh['<VALUE>']\n","     #   .shift(1).rolling(window = 30).mean())/dataset_sh['<VALUE>'].shift(1).rolling(window = 30).mean())+((dataset_sh['<VALUE>'].shift(1).rolling(window = 5).mean()- dataset_sh['<VALUE>']\n","      #  .shift(1).rolling(window = 90).mean())/dataset_sh['<VALUE>'].shift(1).rolling(window = 90).mean())+((dataset_sh['<VALUE>'].shift(1).rolling(window = 5).mean()-dataset_sh['<VALUE>']\n","       # .shift(1).rolling(window = 180).mean())/dataset_sh['<VALUE>'].shift(1).rolling(window = 180).mean())+((dataset_sh['<VALUE>'].shift(1).rolling(window = 5).mean()-dataset_sh['<VALUE>'].shift(1).rolling(window = 365).mean())/dataset_sh['<VALUE>'].shift(1).rolling(window = 365).mean())\n","    \n","    shakhes_kol =  dataset_sh.rename(columns={'<CLOSE>':'SHAKHES','<VOL>':'VOL-SHAKHES','<VALUE>':'VALUE-SHAKHES','<NUM>':'NUM-SHAKHES'})\n","    \n","    #how={'SHAKHES':'last','VOL-SHAKHES':'sum','VALUE-SHAKHES':'sum','NUM-SHAKHES':'sum'}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n8FQRvgRZc4T"},"source":["# **def technical in TA-LIB**"]},{"cell_type":"code","metadata":{"id":"KC3zTZHPk3cH"},"source":["timeper=[3]\n","#periods =np.array([14], dtype=float)\n","def vMAv():\n","  for x in timeper:\n","    data[\"v/{0}MAv\".format(x)] = (data['<VOL>'])/data['<VOL>'].shift(1).rolling(window = int(x)).mean()  #NORMAL\n","\n","def MAmm():\n","  for x in timeper:\n","    data[\"{0}MAm/m\".format(x)] =((data['MID'].shift(1).rolling(window = int(x)).mean())/data['MID']) #NORMAL\n","\n","def Overlap_Studies_Functions():\n","  data['upperband'], data['middleband'], data['lowerband'] = talib.BBANDS(data['<CLOSE>'], timeperiod=14, nbdevup=2, nbdevdn=2, matype=0)\n","  data[\"HT_TRENDLINE\"] =talib.HT_TRENDLINE(data['<CLOSE>'])\n","  data[\"mama\"],data[\"fama\"]= talib.MAMA(data['<CLOSE>'], fastlimit=0.5, slowlimit=0.05)\n","  #data[\"MAVP\"] =talib.MAVP(data['<CLOSE>'], periods, minperiod=2, maxperiod=30, matype=0)\n","  data['SAR'] = (talib.SAR(np.log(data['<HIGH>']),np.log(data['<LOW>']), acceleration=0.02, maximum=0.2))/data['<CLOSE>']#.pct_change()\n","  data['SAREXT'] = talib.SAREXT(np.log(data['<HIGH>']),np.log(data['<LOW>']), startvalue=0, offsetonreverse=0, accelerationinitlong=0.02, accelerationlong=0.02, accelerationmaxlong=0.2, accelerationinitshort=0.02, accelerationshort=0.02, accelerationmaxshort=0.2)\n","\n","  for x in timeper:\n","    data[\"DEMA{0}\".format(x)] =(talib.DEMA(data['<CLOSE>'] , timeperiod = int(x)))/data['<CLOSE>']\n","    data[\"EMA{0}\".format(x)] =(talib.EMA(data['<CLOSE>'] , timeperiod = int(x)))/data['<CLOSE>']\n","    data[\"KAMA{0}\".format(x)] =(talib.KAMA(data['<CLOSE>'] , timeperiod = int(x)))/data['<CLOSE>']\n","    data[\"MA{0}\".format(x)] =(talib.MA(data['<CLOSE>'] , timeperiod = int(x)))/data['<CLOSE>']\n","    data[\"MIDPOINT{0}\".format(x)] =(talib.MIDPOINT(data['<CLOSE>'] , timeperiod = int(x)))/data['<CLOSE>']\n","    data[\"MIDPRICE{0}\".format(x)] =(talib.MIDPRICE(data['<HIGH>'],data['<LOW>'] , timeperiod = int(x)))/data['<CLOSE>']\n","    data[\"SMA{0}\".format(x)] =(talib.SMA(data['<CLOSE>'] ,timeperiod = int(x)))/data['<CLOSE>']\n","    data[\"T3{0}\".format(x)] =(talib.T3(data['<CLOSE>'] ,timeperiod = int(x), vfactor=0))/data['<CLOSE>']\n","    data[\"TEMA{0}\".format(x)] =(talib.TEMA(data['<CLOSE>'] ,timeperiod = int(x)))/data['<CLOSE>']\n","    data[\"TRIMA{0}\".format(x)] =(talib.TRIMA(data['<CLOSE>'] ,timeperiod = int(x)))/data['<CLOSE>']\n","    data[\"WMA{0}\".format(x)] =(talib.WMA(data['<CLOSE>'] ,timeperiod = int(x)))/data['<CLOSE>']\n","\n"," \n","\n","def Momentum_Indicator_Functions():\n","  data[\"APO\"]=(talib.APO(data['<CLOSE>'], fastperiod=9, slowperiod=26, matype=0))/data['<CLOSE>']\n","  #data[\"BOP\"] =talib.BOP( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"macd\"], data[\"macdSignal\"], data[\"macdHist\"] = talib.MACD(data['<CLOSE>'], fastperiod=9, slowperiod=26, signalperiod=12)\n","  data[\"PPO\"]=talib.PPO(data['<CLOSE>'], fastperiod=12, slowperiod=26, matype=0)\n","  #data[\"slowk\"], data[\"slowd\"]= talib.STOCH(data['<HIGH>'],data['<LOW>'],data['<CLOSE>'],fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n","  #data[\"slowkf\"], data[\"slowdf\"]= talib.STOCHF(data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], fastk_period=5, fastd_period=3, fastd_matype=0)\n","  data[\"fastkrsi\"], data[\"fastdrsi\"]= talib.STOCHRSI (data['<CLOSE>'],timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)\n","  data[\"ULTOSC\"] =talib.ULTOSC(data['<HIGH>'],data['<LOW>'] ,data['<CLOSE>'],timeperiod1=7, timeperiod2=14, timeperiod3=28) \n","\n","  for x in timeper:\n","    data[\"ADX{0}\".format(x)] =talib.ADX(data['<HIGH>'],data['<LOW>'] ,data['<CLOSE>'] ,timeperiod = int(x))\n","    data[\"ADXR{0}\".format(x)] =talib.ADXR(data['<HIGH>'],data['<LOW>'] ,data['<CLOSE>'] ,timeperiod = int(x))\n","    data[\"AROONOSC{0}\".format(x)] =talib.AROONOSC(data['<HIGH>'],data['<LOW>'] ,timeperiod = int(x))\n","    data[\"CCI{0}\".format(x)] =talib.CCI(data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], timeperiod = int(x))\n","    data[\"CMO{0}\".format(x)] =talib.CMO(data['<CLOSE>'], timeperiod = int(x))\n","    data[\"DX{0}\".format(x)] =talib.DX(data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], timeperiod = int(x))\n","    data[\"MFI{0}\".format(x)] =talib.MFI(data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], data['<VOL>'], timeperiod = int(x))\n","    data[\"MINUS_DI{0}\".format(x)] =talib.MINUS_DI(data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], timeperiod = int(x))\n","    data[\"MINUS_DM{0}\".format(x)] =(talib.MINUS_DM(data['<HIGH>'],data['<LOW>'], timeperiod = int(x)))/data['<CLOSE>']\n","    data[\"MOM{0}\".format(x)] =(talib.MOM(data['<CLOSE>'], timeperiod=int(x))) /data['<CLOSE>']\n","    data[\"PLUS_DI{0}\".format(x)] =talib.PLUS_DI(data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], timeperiod = int(x))\n","    data[\"PLUS_DM{0}\".format(x)] =(talib.PLUS_DM(data['<HIGH>'],data['<LOW>'], timeperiod = int(x)))/data['<CLOSE>']\n","    data[\"ROC{0}\".format(x)] =(talib.ROC(data['<CLOSE>'], timeperiod=int(x)))/data['<CLOSE>'] \n","    data[\"RSI{0}\".format(x)] =talib.RSI(data['<CLOSE>'], timeperiod=int(x)) \n","    data[\"TRIX{0}\".format(x)] =talib.TRIX(data['<CLOSE>'], timeperiod=int(x)) \n","    data[\"WILLR{0}\".format(x)] =talib.WILLR(data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], timeperiod=int(x)) \n","\n","\n","def Volume_Indicator_Functions():\n","  #data[\"AD\"] =talib.AD(data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], data['<VOL>'])\n","  #data['AD']=data['AD'].pct_change()\n","  #data[\"ADOSC\"] =talib.ADOSC(data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], data['<VOL>'], fastperiod=3, slowperiod=10)\n","  #data['ADOSC']=data['ADOSC'].pct_change()\n","  data[\"OBV\"] =(talib.OBV(data['<CLOSE>'], data['<VOL>']))/data['<CLOSE>']\n","  #data['OBV']=data['OBV'].pct_change()\n","\n","def Volatility_Indicator_Functions():\n","  data[\"TRANGE\"] =(talib.TRANGE(data['<HIGH>'],data['<LOW>'],data['<CLOSE>']))/data['<CLOSE>']\n","  #data['TRANGE']=data['TRANGE'].pct_change()\n","  for x in timeper:\n","    data[\"ATR{0}\".format(x)] =(talib.ATR(data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], timeperiod=int(x)))/data['<CLOSE>']\n","    data[\"NATR{0}\".format(x)] =talib.NATR(data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], timeperiod=int(x)) \n","\n","def Cycle_Indicator_Functions():\n","  data[\"HT_DCPERIOD\"] =talib.HT_DCPERIOD(data['<CLOSE>'])\n","  data[\"HT_DCPHASE\"] =talib.HT_DCPHASE(data['<CLOSE>'])\n","  data[\"inphase\"], data[\"quadrature\"] =talib.HT_PHASOR(data['<CLOSE>'])\n","  data[\"HT_PHASOR\"]=data[\"inphase\"]/data[\"quadrature\"] ###################\n","  data[\"sine\"], data[\"leadsine\"] =talib.HT_SINE(data['<CLOSE>'])\n","  data[\"HT_SINE\"]=data[\"sine\"]- data[\"leadsine\"]#####################\n","  data[\"HT_TRENDMODE\"] =talib.HT_TRENDMODE(data['<CLOSE>'])+1\n","\n","def Pattern_Recognition_Functions():\n","  data[\"CDL2CROWS\"] =talib.CDL2CROWS( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDL3BLACKCROWS\"] =talib.CDL3BLACKCROWS( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDL3INSIDE\"] =talib.CDL3INSIDE( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDL3LINESTRIKE\"] =talib.CDL3LINESTRIKE( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDL3OUTSIDE\"] =talib.CDL3OUTSIDE( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDL3STARSINSOUTH\"] =talib.CDL3STARSINSOUTH( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDL3WHITESOLDIERS\"] =talib.CDL3WHITESOLDIERS( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLABANDONEDBABY\"] =talib.CDLABANDONEDBABY( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], penetration=0)\n","  data[\"CDLADVANCEBLOCK\"] =talib.CDLADVANCEBLOCK( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLBELTHOLD\"] =talib.CDLBELTHOLD( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLBREAKAWAY\"] =talib.CDLBREAKAWAY( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLCLOSINGMARUBOZU\"] =talib.CDLCLOSINGMARUBOZU( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLCONCEALBABYSWALL\"] =talib.CDLCONCEALBABYSWALL( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLCOUNTERATTACK\"] =talib.CDLCOUNTERATTACK( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLDARKCLOUDCOVER\"] =talib.CDLDARKCLOUDCOVER( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'] ,penetration=0)\n","  data[\"CDLDOJI\"] =talib.CDLDOJI(data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLDOJISTAR\"] =talib.CDLDOJISTAR( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLDRAGONFLYDOJI\"] =talib.CDLDRAGONFLYDOJI( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLENGULFING\"] =talib.CDLENGULFING( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLEVENINGDOJISTAR\"] =talib.CDLEVENINGDOJISTAR( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'] ,penetration=0)\n","  data[\"CDLEVENINGSTAR\"] =talib.CDLEVENINGSTAR( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'] ,penetration=0)\n","  data[\"CDLGAPSIDESIDEWHITE\"] =talib.CDLGAPSIDESIDEWHITE( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLGRAVESTONEDOJI\"] =talib.CDLGRAVESTONEDOJI( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLHAMMER\"] =talib.CDLHAMMER( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLHANGINGMAN\"] =talib.CDLHANGINGMAN( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLHARAMI\"] =talib.CDLHARAMI( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLHARAMICROSS\"] =talib.CDLHARAMICROSS( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLHIGHWAVE\"] =talib.CDLHIGHWAVE( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLHIKKAKE\"] =talib.CDLHIKKAKE( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLHIKKAKEMOD\"] =talib.CDLHIKKAKEMOD( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLHOMINGPIGEON\"] =talib.CDLHOMINGPIGEON( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLIDENTICAL3CROWS\"] =talib.CDLIDENTICAL3CROWS( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLINNECK\"] =talib.CDLINNECK( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLINVERTEDHAMMER\"] =talib.CDLINVERTEDHAMMER( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLKICKING\"] =talib.CDLKICKING( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLKICKINGBYLENGTH\"] =talib.CDLKICKINGBYLENGTH( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLLADDERBOTTOM\"] =talib.CDLLADDERBOTTOM( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLLONGLEGGEDDOJI\"] =talib.CDLLONGLEGGEDDOJI( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLLONGLINE\"] =talib.CDLLONGLINE( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLMARUBOZU\"] =talib.CDLMARUBOZU( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLMATCHINGLOW\"] =talib.CDLMATCHINGLOW( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLMATHOLD\"] =talib.CDLMATHOLD( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'] ,penetration=0)\n","  data[\"CDLMORNINGDOJISTAR\"] =talib.CDLMORNINGDOJISTAR( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], penetration=0)\n","  data[\"CDLMORNINGSTAR\"] =talib.CDLMORNINGSTAR( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'], penetration=0)\n","  data[\"CDLONNECK\"] =talib.CDLONNECK( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLPIERCING\"] =talib.CDLPIERCING( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLRICKSHAWMAN\"] =talib.CDLRICKSHAWMAN( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLRISEFALL3METHODS\"] =talib.CDLRISEFALL3METHODS( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLSEPARATINGLINES\"] =talib.CDLSEPARATINGLINES( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLSHOOTINGSTAR\"] =talib.CDLSHOOTINGSTAR( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLSHORTLINE\"] =talib.CDLSHORTLINE( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLSPINNINGTOP\"] =talib.CDLSPINNINGTOP( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLSTALLEDPATTERN\"] =talib.CDLSTALLEDPATTERN( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLSTICKSANDWICH\"] =talib.CDLSTICKSANDWICH( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLTAKURI\"] =talib.CDLTAKURI( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLTASUKIGAP\"] =talib.CDLTASUKIGAP( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLTHRUSTING\"] =talib.CDLTHRUSTING( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLTRISTAR\"] =talib.CDLTRISTAR( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLUNIQUE3RIVER\"] =talib.CDLUNIQUE3RIVER( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLUPSIDEGAP2CROWS\"] =talib.CDLUPSIDEGAP2CROWS( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","  data[\"CDLXSIDEGAP3METHODS\"] =talib.CDLXSIDEGAP3METHODS( data['<OPEN>'],data['<HIGH>'],data['<LOW>'],data['<CLOSE>'])\n","\n","\n","def Statistic_Functions():\n","  for x in timeper:\n","    data[\"BETA{0}\".format(x)] =talib.BETA(data['<HIGH>'],data['<LOW>'], timeperiod=int(x)) \n","    data[\"CORREL{0}\".format(x)] =talib.CORREL(data['<HIGH>'],data['<LOW>'], timeperiod=int(x)) \n","    data[\"LINEARREG{0}\".format(x)] =(talib.LINEARREG(data['<CLOSE>'], timeperiod=int(x)))/data['<CLOSE>']\n","    data[\"LINEARREG_ANGLE{0}\".format(x)] =talib.LINEARREG_ANGLE(data['<CLOSE>'], timeperiod=int(x))\n","    data[\"LINEARREG_INTERCEPT{0}\".format(x)] =(talib.LINEARREG_INTERCEPT(data['<CLOSE>'], timeperiod=int(x)))/data['<CLOSE>']\n","    #data[\"LINEARREG_SLOPE{0}\".format(x)] =(talib.LINEARREG_SLOPE(data['<CLOSE>'], timeperiod=int(x))).pct_change()\n","    data[\"STDDEV{0}\".format(x)] =(talib.STDDEV(data['<CLOSE>'], timeperiod=int(x), nbdev=1))/data['<CLOSE>']\n","    data[\"TSF{0}\".format(x)] =(talib.TSF(data['<CLOSE>'], timeperiod=int(x)))/data['<CLOSE>']\n","    data[\"VAR{0}\".format(x)] =(talib.VAR(data['<CLOSE>'], timeperiod=int(x), nbdev=1))/data['<CLOSE>']\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-SFXtsuwovMn"},"source":["# **Parabolic SAR**"]},{"cell_type":"code","metadata":{"id":"olasPRndl6IZ","executionInfo":{"status":"ok","timestamp":1675582020583,"user_tz":-210,"elapsed":370,"user":{"displayName":"Ali Asghar Yousefian","userId":"17320255365069876391"}}},"source":["def Parabolic_SAR_log():\n","  # Calculate parabolic sar\n","  data['SAR'] = talib.SAR(np.log(data['<HIGH>']),np.log(data['<LOW>']), acceleration=5, maximum=0.5)\n","  # Plot Parabolic SAR with close price\n","  #data[['<CLOSE>', 'SAR']][:500].plot(figsize=(10,5))\n","  #plt.grid()\n","  #plt.show()\n","  # Calculate Tenkan-sen\n","  high_9 = np.log(data['<HIGH>']).rolling(9).max()\n","  low_9 = np.log(data['<LOW>']).rolling(9).min() \n","  data['tenkan_sen_line'] = (high_9 + low_9) /2\n","  data['log_<CLOSE>'] = np.log(data['<CLOSE>'])\n","  # Calculate Kijun-sen\n","  high_26 = np.log(data['<HIGH>']).rolling(26).max()\n","  low_26 = np.log(data['<LOW>']).rolling(26).min()\n","  data['kijun_sen_line'] = (high_26 + low_26) / 2\n","\n","  # Calculate Senkou Span A\n","  data['senkou_spna_A'] = ((data.tenkan_sen_line + data.kijun_sen_line) / 2).shift(26)\n","\n","  # Calculate Senkou Span B\n","  high_52 = np.log(data['<HIGH>']).rolling(52).max()\n","  low_52 = np.log(data['<HIGH>']).rolling(52).min()\n","  data['senkou_spna_B'] = ((high_52 + low_52) / 2).shift(26)\n","\n","  # Calculate Chikou Span B\n","  data['chikou_span'] = np.log(data['<CLOSE>']).shift(-26)\n","\n","  komu_cloud = data[['log_<CLOSE>','SAR']].plot(figsize=(12, 7))\n","\n","  komu_cloud.fill_between(data.index, data.senkou_spna_A, data.senkou_spna_B,where=data.senkou_spna_A >= data.senkou_spna_B, color='lightgreen')\n","\n","  komu_cloud.fill_between(data.index, data.senkou_spna_A, data.senkou_spna_B,where=data.senkou_spna_A< data.senkou_spna_B, color='lightcoral')\n","  plt.grid()\n","\n","  plt.legend()\n","  plt.show()\n","\n","  data['log_signal'] = 0\n","  data.loc[(data['log_<CLOSE>'] > data.senkou_spna_A) & (data['log_<CLOSE>'] > data.senkou_spna_B) & (data['log_<CLOSE>'] > data.SAR), 'log_signal'] = 1\n","\n","  data.loc[(data['log_<CLOSE>'] < data.senkou_spna_A) & (data['log_<CLOSE>'] <data.senkou_spna_B) & (data['log_<CLOSE>'] < data.SAR), 'log_signal'] = -1\n","  \n","  data['log_signal'].value_counts()\n","\n","  # Calculate daily returns\n","  daily_returns = data['log_<CLOSE>'].pct_change()\n","\n","  # Calculate strategy returns\n","  strategy_returns = daily_returns *data['log_signal'].shift(1)\n","  # Calculate cumulative returns \n","  (strategy_returns+1).cumprod().plot(figsize=(10,5))\n","\n","  # Plot the strategy returns\n","  plt.xlabel('log_Date')\n","  plt.ylabel('log_Strategy Returns (%)')\n","  plt.grid()\n","  plt.show()\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_Yp78KgouFR","executionInfo":{"status":"ok","timestamp":1675582020584,"user_tz":-210,"elapsed":3,"user":{"displayName":"Ali Asghar Yousefian","userId":"17320255365069876391"}}},"source":["def Parabolic_SAR():\n","\n","  # Calculate parabolic sar\n","  data['SAR'] = talib.SAR(data['<HIGH>'],data['<LOW>'], acceleration=0.02, maximum=0.2)\n","  # Plot Parabolic SAR with close price\n","  #data[['<CLOSE>', 'SAR']][:500].plot(figsize=(10,5))\n","  #plt.grid()\n","  #plt.show()\n","  # Calculate Tenkan-sen\n","  high_9 = data['<HIGH>'].rolling(9).max()\n","  low_9 = data['<LOW>'].rolling(9).min() \n","  data['tenkan_sen_line'] = (high_9 + low_9) /2\n","\n","  # Calculate Kijun-sen\n","  high_26 = data['<HIGH>'].rolling(26).max()\n","  low_26 = data['<LOW>'].rolling(26).min()\n","  data['kijun_sen_line'] = (high_26 + low_26) / 2\n","\n","  # Calculate Senkou Span A\n","  data['senkou_spna_A'] = ((data.tenkan_sen_line + data.kijun_sen_line) / 2).shift(26)\n","\n","  # Calculate Senkou Span B\n","  high_52 = data['<HIGH>'].rolling(52).max()\n","  low_52 = data['<HIGH>'].rolling(52).min()\n","  data['senkou_spna_B'] = ((high_52 + low_52) / 2).shift(26)\n","\n","  # Calculate Chikou Span B\n","  data['chikou_span'] = data['<CLOSE>'].shift(-26)\n","\n","  komu_cloud = data[['<CLOSE>','SAR']].plot(figsize=(12, 7))\n","\n","  komu_cloud.fill_between(data.index, data.senkou_spna_A, data.senkou_spna_B,where=data.senkou_spna_A >= data.senkou_spna_B, color='lightgreen')\n","\n","  komu_cloud.fill_between(data.index, data.senkou_spna_A, data.senkou_spna_B,where=data.senkou_spna_A < data.senkou_spna_B, color='lightcoral')\n","  plt.grid()\n","\n","  plt.legend()\n","  plt.show()\n","\n","  data['signal'] = 0\n","  data.loc[(data['<CLOSE>'] > data.senkou_spna_A) & (data['<CLOSE>'] > data.senkou_spna_B) & (data['<CLOSE>'] > data.SAR), 'signal'] = 1\n","\n","  data.loc[(data['<CLOSE>'] < data.senkou_spna_A) & (data['<CLOSE>'] <data.senkou_spna_B) & (data['<CLOSE>'] < data.SAR), 'signal'] = -1\n","  \n","  data['signal'].value_counts()\n","\n","  # Calculate daily returns\n","  daily_returns = data['<CLOSE>'].pct_change()\n","\n","  # Calculate strategy returns\n","  strategy_returns = daily_returns *data['signal'].shift(1)\n","  # Calculate cumulative returns \n","  (strategy_returns+1).cumprod().plot(figsize=(10,5))\n","\n","  # Plot the strategy returns\n","  plt.xlabel('Date')\n","  plt.ylabel('Strategy Returns (%)')\n","  plt.grid()\n","  plt.show()\n","\n"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"myrJnKPSo3yO"},"source":["# **def tech Dataframe**"]},{"cell_type":"code","metadata":{"id":"prZPT9M2ufrn","cellView":"code"},"source":["#@title Default title text\n","def tech_data():\n"," \n","    global dataset\n","    global dataset_g\n","    global dataset_gg\n","    global data_t\n","    global data\n","\n","    global df\n","    global tech_dataset_d \n","    #global tech_dataset_w\n","    #global tech_dataset_m\n","    #global tech_dataset_y\n","\n","    loc='/content/drive/My Drive/Colab Notebooks/stock/'+'{}'.format(a)+'-'+'ت'+'.xls' \n","    loc_2=loc\n","    \n","\n","    cols_X_1 = [1,2,3,4,5,6,7,8,9] #open/high/low/close\n","    dataset= pd.read_excel(loc_2, usecols=cols_X_1)\n","    dataset=dataset.dropna()\n","    dataset=dataset[['<DTYYYYMMDD>','<OPEN>', '<HIGH>', '<LOW>', '<CLOSE>','<VOL>','<VALUE>']]\n"," \n","    y = dataset['<VOL>']\n","    dataset['<VOL-filter>'] = y.between(y.quantile(.03), y.quantile(.97))\n","    dataset.drop( dataset[ dataset['<VOL-filter>'] == False ].index , inplace=True)\n","    del dataset['<VOL-filter>']\n","\n","\n","    #dataset['<VOL_av>'] = dataset['<VOL>']*1\n","    \n","    dataset['<DTYYYYMMDD>'] = pd.to_datetime(dataset['<DTYYYYMMDD>'], format='%Y%m%d').dt.strftime(\"%Y-%m-%d\"); dataset\n","    \n","    dataset['<DTYYYYMMDD>'] = pd.to_datetime(dataset['<DTYYYYMMDD>'])\n","    dataset.set_index('<DTYYYYMMDD>', inplace=True)\n","    dataset.sort_index(inplace=True)\n","    \n","    dataset_g=dataset.dropna()\n","\n","    \"\"\"\n","    times = sorted(dataset_g.index.values)  # get the times\n","    first_20pct = sorted(dataset_g.index.values)[int(0.20*len(times))]\n","    first_40pct = sorted(dataset_g.index.values)[int(0.40*len(times))]\n","    first_60pct = sorted(dataset_g.index.values)[int(0.60*len(times))]\n","    first_80pct = sorted(dataset_g.index.values)[int(0.80*len(times))]\n","\n","    a1= dataset_g[(dataset_g.index < first_20pct)]\n","    a2= dataset_g[( first_20pct <= dataset_g.index) & (dataset_g.index < first_40pct)]\n","    a3= dataset_g[( first_40pct <= dataset_g.index) & (dataset_g.index < first_60pct)]\n","    a4= dataset_g[( first_60pct <= dataset_g.index) & (dataset_g.index < first_80pct)]\n","    a5= dataset_g[( first_80pct <= dataset_g.index)]\n","\n","    b1=a1[(np.abs(stats.zscore(a1)) < 3).all(axis=1)]\n","    b2=a2[(np.abs(stats.zscore(a2)) < 3).all(axis=1)]\n","    b3=a3[(np.abs(stats.zscore(a3)) < 3).all(axis=1)]\n","    b4=a4[(np.abs(stats.zscore(a4)) < 3).all(axis=1)]\n","    b5=a5[(np.abs(stats.zscore(a5)) < 3).all(axis=1)]\n","                \n","    dataset_gg = pd.concat([b1, b2, b3,b4,b5 ])\n","    data=dataset_gg.copy()\n","    \"\"\"\n","\n","    data=dataset_g.copy()\n","\n","    data['MID'] = ((data['<HIGH>'] + data['<LOW>'])/2)\n","    data['MID_pct']=data['MID'].pct_change() \n","    #data['MID-Y']=data['MID'].rolling(window = 3).mean()\n","    \n","    data['H-L'] = np.floor(100*((data['<HIGH>'] - data['<LOW>'])/data['MID']))+(np.abs((np.floor(100*((data['<HIGH>'] - data['<LOW>'])/data['MID']))).min()))+1 \n","    data['H-O'] = np.floor(100*((data['<HIGH>'] - data['<OPEN>'])/data['MID']))+(np.abs((np.floor(100*((data['<HIGH>'] - data['<OPEN>'])/data['MID']))).min()))+1\n","    data['H-C'] = np.floor(100*((data['<HIGH>'] - data['<CLOSE>'])/data['MID']))+(np.abs((np.floor(100*((data['<HIGH>'] - data['<CLOSE>'])/data['MID']))).min()))+1\n","    \n","    data['H-L-1'] = data['H-L'].shift(1)\n","    data['H-O-1'] = data['H-O'].shift(1)\n","    data['H-C-1'] = data['H-C'].shift(1)\n","\n","    data['H-L-2'] = data['H-L'].shift(2)\n","    data['H-O-2'] = data['H-O'].shift(2)\n","    data['H-C-2'] = data['H-C'].shift(2)\n","    \n","\n","    vMAv()\n","    MAmm()\n","    Overlap_Studies_Functions()\n","    Momentum_Indicator_Functions()\n","    Volume_Indicator_Functions()\n","    Volatility_Indicator_Functions()\n","    Cycle_Indicator_Functions()\n","    #Pattern_Recognition_Functions()\n","    Statistic_Functions()\n","\n","    data['MACDD']= data['macd']/ data['macdSignal']\n","    data['macdHist2']= data['macdHist']/data['MID']\n","    data=data.drop(['macd','macdSignal','macdHist'], axis=1)\n","\n","    \n","    data['BBAND']=  (data['upperband']-data['<CLOSE>'])/(data['upperband']-data['lowerband'])\n","    data=data.drop(['upperband','middleband','lowerband'], axis=1)\n","    \n","    data['HT_TRENDLINE_pct']=data['HT_TRENDLINE'].pct_change()########################\n","    data[\"mama_fama\"]=(data[\"mama\"]-data[\"fama\"])/(data[\"mama\"]-data['MID'])######################\n","    data=data.drop(['HT_TRENDLINE','mama','fama','inphase','quadrature'], axis=1)\n","\n","\n","    times = sorted(data.index.values)  # get the times\n","    first_20pct = sorted(data.index.values)[int(0.20*len(times))]\n","    first_40pct = sorted(data.index.values)[int(0.40*len(times))]\n","    first_60pct = sorted(data.index.values)[int(0.60*len(times))]\n","    first_80pct = sorted(data.index.values)[int(0.80*len(times))]\n","\n","    a1= data[(data.index < first_20pct)]\n","    a2= data[( first_20pct <= data.index) & (data.index < first_40pct)]\n","    a3= data[( first_40pct <= data.index) & (data.index < first_60pct)]\n","    a4= data[( first_60pct <= data.index) & (data.index < first_80pct)]\n","    a5= data[( first_80pct <= data.index)]\n","\n","    b1=a1[(np.abs(stats.zscore(a1)) < 3).all(axis=1)]\n","    b2=a2[(np.abs(stats.zscore(a2)) < 3).all(axis=1)]\n","    b3=a3[(np.abs(stats.zscore(a3)) < 3).all(axis=1)]\n","    b4=a4[(np.abs(stats.zscore(a4)) < 3).all(axis=1)]\n","    b5=a5\n","                \n","    dataset_gg = pd.concat([b1, b2, b3,b4,b5 ])\n","    \n","\n","\n","    tech_dataset_d = dataset_gg.copy()\n","\n","\n","\n","    basedata_d=dolar.merge(tech_dataset_d, right_index=True,left_index=True, how='left', sort=False)\n","    basedata_d_s=seke.merge(basedata_d, right_index=True,left_index=True, how='left', sort=False)\n","    basedata_d_s_sh=shakhes_kol.merge(basedata_d_s, right_index=True,left_index=True, how='left', sort=False).dropna()\n","    data_1=basedata_d_s_sh.copy()\n","    data_1['mid/seke']= data_1['MID']/data_1['seke']\n","    data_1['mid/dolar']= data_1['MID']/data_1['dollar']\n","    data_1['LOG-mid/LOG-SHAKHES']=np.log(data_1['MID'])/np.log(data_1['SHAKHES'])\n","    \n","    data_1['seke']= np.log(data_1['seke'])\n","    data_1['dollar']= np.log(data_1['dollar'])\n","    data_1['SHAKHES']=np.log(data_1['SHAKHES'])\n"," \n","    f=data_1\n","    cols_2 = [col for col in f.columns if col not in ['<OPEN>','<HIGH>','<LOW>','<CLOSE>']]\n","    f_1=f[cols_2]\n","    f_2=f[['<OPEN>','<HIGH>','<LOW>','<CLOSE>']]\n","    how_2={'<OPEN>':'first', '<HIGH>': 'max','<LOW>': 'min','<CLOSE>': 'last'} \n","    basedata_1 = f_1.resample('w').mean()\n","    basedata_2 = (f_2.resample('w').apply(how_2))#.pct_change()                              # Weekly resample\n","    \n","    basedata_3=basedata_1.merge(basedata_2, right_index=True,left_index=True, how='left', sort=False)\n","\n","    \n","    \n","    data_t=basedata_3.dropna()\n","    #data_t=data_1.dropna()\n","\n","\n","\n","\n","\n","    \n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vNHPszcXufrr","colab":{"base_uri":"https://localhost:8080/","height":503},"executionInfo":{"status":"error","timestamp":1654846741237,"user_tz":-270,"elapsed":5244,"user":{"displayName":"Ali Asghar Yousefian","userId":"17320255365069876391"}},"outputId":"285d3818-8004-46e0-f05d-c8307c8e1ad5"},"source":["a=str('لبوتان')\n","dollar()\n","sekke()\n","shakhes()\n","tech_data()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-69111d0c3c5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdollar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msekke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshakhes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtech_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-af1f1dd7480d>\u001b[0m in \u001b[0;36mshakhes\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mcols_X_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#open/high/low/close\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdataset_sh\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols_X_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdataset_sh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_sh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mdataset_sh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_sh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<DTYYYYMMDD>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<CLOSE>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<VOL>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<VALUE>'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'<NUM>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         raise ValueError(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \"\"\"\n\u001b[1;32m     23\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/compat/_optional.py\u001b[0m in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: Pandas requires version '1.2.0' or newer of 'xlrd' (version '1.1.0' currently installed).","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","metadata":{"id":"1dyDKShzuC5x","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1610260299612,"user_tz":-210,"elapsed":283128,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"b5ff1cc1-1176-4457-8984-f0cf6554d047"},"source":["data_t.to_excel(\"data3.xlsx\",sheet_name='data')\n","files.download('data3.xlsx') "],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_10092f57-9d1f-44ca-a5ed-326626303fd1\", \"data3.xlsx\", 468919)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"AsvuFSqRufr3"},"source":["SEQ_LEN = 10  # how long of a preceeding sequence to collect for RNN\n","FUTURE_PERIOD_PREDICT = 1  # how far into the future are we trying to predict?\n","RATIO_TO_PREDICT = \"MID\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"ENnKuq_-ufr7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260299616,"user_tz":-210,"elapsed":283118,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"e363d551-0e8d-4c86-b26a-99b5bf984976"},"source":["init_df_x=data_t.copy()\n","main_df=(data_t.copy()).dropna() \n","main_df['future'] = main_df[RATIO_TO_PREDICT].shift(-FUTURE_PERIOD_PREDICT)\n","print(main_df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["                SHAKHES   VOL-SHAKHES  ...    <CLOSE>         future\n","<DTYYYYMMDD>                           ...                          \n","2008-12-21     9.088664  1.681142e+07  ...     386.83     394.333333\n","2008-12-28     9.080529  2.529414e+07  ...     389.31     385.375000\n","2009-01-04     9.068769  2.467424e+07  ...     389.31     411.000000\n","2009-01-25     9.051811  6.157285e+07  ...     413.92     401.000000\n","2009-02-01     9.048891  3.085831e+07  ...     413.15     389.000000\n","...                 ...           ...  ...        ...            ...\n","2020-08-02    14.487772  1.060202e+10  ...  117380.00  115367.500000\n","2020-08-09    14.521065  9.076221e+09  ...  112850.00  102847.500000\n","2020-08-16    14.468707  6.312196e+09  ...   98420.00   90913.000000\n","2020-08-23    14.378847  8.468331e+09  ...   90330.00   86653.333333\n","2020-08-30    14.321419  7.199384e+09  ...   89170.00            NaN\n","\n","[483 rows x 87 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FDWSGn0YufsA"},"source":["def classify(current, future):\n","    if ((float(future) - float(current))/ float(current))>0.04:\n","        return 4\n","    if  0<=((float(future) - float(current))/ float(current))<0.04:\n","        return 3\n","    if  -0.04<=((float(future) - float(current))/ float(current))<0:\n","        return 2\n","    if ((float(future) - float(current))/ float(current))<-0.04:\n","        return 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UyXSd8t5ufsF"},"source":["main_df=main_df.dropna()\n","main_df['target'] = list(map(classify, main_df[RATIO_TO_PREDICT], main_df['future']))\n","main_df_for_filter=main_df.copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y88TCZxNufsI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260299623,"user_tz":-210,"elapsed":283107,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"63261cb2-31c7-4b8d-dd62-7c2525c24922"},"source":["times = sorted(main_df.index.values)  # get the times\n","last_10pct = sorted(main_df.index.values)[-int(0.1*len(times))]  # get the last 10% of the times\n"," \n","validation_main_df = main_df[(main_df.index >= last_10pct)]  # make the validation data where the index is in the last 10%\n","main_df = main_df[(main_df.index < last_10pct)]  # now the main_df is all the data up to the last 10%\n"," \n","main_df.head()\n","print(validation_main_df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["                SHAKHES   VOL-SHAKHES  ...         future  target\n","<DTYYYYMMDD>                           ...                       \n","2019-09-29    12.661136  5.097084e+09  ...   26718.500000       4\n","2019-10-06    12.691207  6.349385e+09  ...   25314.400000       1\n","2019-10-13    12.673881  3.905672e+09  ...   23088.750000       1\n","2019-10-20    12.644008  2.906167e+09  ...   20889.250000       1\n","2019-10-27    12.627829  2.517655e+09  ...   21703.500000       3\n","2019-11-03    12.638917  2.642586e+09  ...   22820.750000       4\n","2019-11-10    12.626964  2.380604e+09  ...   23011.400000       3\n","2019-11-17    12.629306  2.353491e+09  ...   23021.200000       3\n","2019-11-24    12.627279  2.006870e+09  ...   24228.600000       4\n","2019-12-01    12.652360  2.902458e+09  ...   23595.900000       2\n","2019-12-08    12.690694  3.448368e+09  ...   24825.200000       4\n","2019-12-15    12.737849  4.002630e+09  ...   26247.400000       4\n","2019-12-22    12.766976  4.030510e+09  ...   27658.375000       4\n","2019-12-29    12.808090  4.321255e+09  ...   31391.666667       4\n","2020-01-05    12.830067  5.641514e+09  ...   30225.875000       2\n","2020-01-12    12.799222  3.873533e+09  ...   33741.700000       4\n","2020-01-19    12.903064  6.375297e+09  ...   41313.333333       4\n","2020-01-26    12.931430  6.059122e+09  ...   41274.125000       2\n","2020-02-02    12.961120  6.665753e+09  ...   42146.700000       3\n","2020-02-09    13.009063  7.723302e+09  ...   45002.625000       4\n","2020-02-16    13.009980  6.056286e+09  ...   48948.200000       4\n","2020-02-23    13.084883  5.212793e+09  ...   47165.875000       2\n","2020-03-01    13.148106  6.266751e+09  ...   45994.000000       2\n","2020-03-08    13.207431  5.373160e+09  ...   40916.900000       1\n","2020-03-15    13.150216  4.304766e+09  ...   42677.000000       4\n","2020-03-22    13.136496  3.955030e+09  ...   44614.666667       4\n","2020-03-29    13.162983  4.408346e+09  ...   44692.666667       3\n","2020-04-05    13.240891  6.848907e+09  ...   44628.900000       2\n","2020-04-12    13.297911  6.490889e+09  ...   50160.300000       4\n","2020-04-19    13.385700  6.278193e+09  ...   59105.100000       4\n","2020-04-26    13.525406  6.274190e+09  ...   62306.875000       4\n","2020-05-03    13.691480  5.064354e+09  ...   61889.800000       2\n","2020-05-10    13.815370  1.042369e+10  ...   54750.000000       1\n","2020-05-17    13.820389  9.784651e+09  ...   57083.500000       4\n","2020-05-24    13.808169  1.020218e+10  ...   56009.875000       2\n","2020-05-31    13.766247  9.465515e+09  ...   55643.875000       2\n","2020-06-07    13.863681  8.721875e+09  ...   64470.700000       4\n","2020-06-14    13.957673  9.954037e+09  ...   71127.333333       4\n","2020-06-21    14.025072  6.690532e+09  ...   76719.600000       4\n","2020-06-28    14.166898  8.472173e+09  ...   75220.625000       2\n","2020-07-05    14.263224  9.834233e+09  ...   89261.666667       4\n","2020-07-12    14.385922  1.116177e+10  ...  101914.000000       4\n","2020-07-19    14.423346  1.062910e+10  ...  121867.500000       4\n","2020-07-26    14.472507  7.796844e+09  ...  118776.666667       2\n","2020-08-02    14.487772  1.060202e+10  ...  115367.500000       2\n","2020-08-09    14.521065  9.076221e+09  ...  102847.500000       1\n","2020-08-16    14.468707  6.312196e+09  ...   90913.000000       1\n","2020-08-23    14.378847  8.468331e+09  ...   86653.333333       1\n","\n","[48 rows x 88 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aDCgJa2bLqjl","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1610260300512,"user_tz":-210,"elapsed":283992,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"1e119ceb-a15d-4cc5-9831-8bf60dac054c"},"source":["main_df.to_excel(\"main_df.xlsx\",sheet_name='main_df')\n","files.download('main_df.xlsx') "],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_0bbc4255-f729-4885-bed8-4d9c366d89b3\", \"main_df.xlsx\", 424707)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"lhULj0CEufsP"},"source":["def preprocess_df(df):\n"," \n","  for co in df.columns:\n","    if co == \"future\":\n","      df = df.drop(\"future\", 1)  # don't need this anymore.\n","    if co == \"MID\":\n","      df = df.drop(\"MID\", 1)\n"," \n","  \n","  df1= df[['SHAKHES', 'VOL-SHAKHES','NUM-SHAKHES','VALUE-SHAKHES','seke','dollar','<OPEN>','<HIGH>','<LOW>','<CLOSE>','<VOL>','<VALUE>']]\n","  df2 = df1.pct_change()\n","  df2=df2.replace([np.inf, -np.inf], np.nan).dropna( how=\"all\")\n","  df2.dropna(inplace=True)\n"," \n","  for col in df2.columns:\n","    df2[col] = preprocessing.scale(df2[col].values)  # scale between 0 and 1.\n"," \n","  df2.dropna(inplace=True)  # cleanup again... jic.\n","  df3=df.drop(['SHAKHES', 'VOL-SHAKHES','NUM-SHAKHES','VALUE-SHAKHES','seke','dollar','<OPEN>','<HIGH>','<LOW>','<CLOSE>','<VOL>','<VALUE>'], axis=1)\n","  #df3=df3.iloc[1:]\n","  for col in df3.columns:  # go through all of the columns\n","      if col != \"target\": # normalize all ... except for the target itself!\n","        df3[col] = preprocessing.scale(df3[col].values)\n","        #df3[col]=(df3[col]-df3[col].min())/(df3[col].max()-df3[col].min())\n"," \n","  df4=df2.merge(df3, right_index=True,left_index=True, how='left', sort=False)\n"," \n","  df5=df4[(np.abs(stats.zscore(df4)) < 3).all(axis=1)]\n","  df5.dropna(inplace=True)  # cleanup again... jic. # cleanup again... jic.\n"," \n","  sequential_data = []  # this is a list that will CONTAIN the sequences\n","  prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n"," \n","  for i in df4.values:  # iterate over the values\n","      prev_days.append([n for n in i[:-1]])  # store all but the target\n","      if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n","          sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n"," \n","  random.shuffle(sequential_data)  # shuffle for good measure.\n"," \n","  buys = []  # list that will store our buy sequences and targets\n","  nothing=[] #kari nakon\n","  sells = []  # list that will store our sell sequences and targets\n"," \n","  for seq, target in sequential_data:  # iterate over the sequential data\n","      if target == 1 :  # if it's a \"not buy\"\n","          sells.append([seq, target])  # append to sells list\n","      if target == 2 or 3  :  # if it's a \"not buy\"\n","          nothing.append([seq, target])  # append to nothing list\n","      if target == 4 :  # otherwise if the target is a 1...\n","          buys.append([seq, target])  # it's a buy!\n"," \n","  random.shuffle(buys)  # shuffle the buys\n","  random.shuffle(nothing)\n","  random.shuffle(sells)  # shuffle the sells!\n","  \n","  lower = min(len(buys), len(sells),len(nothing))  # what's the shorter length?\n","  buys = buys[:lower]  # make sure both lists are only up to the shortest length.\n","  nothing = nothing[:lower]\n","  sells = sells[:lower]  # make sure both lists are only up to the shortest length.\n"," \n","  sequential_data = buys+sells+nothing#+nothing2 # add them together\n","  random.shuffle(sequential_data)  # another shuffle, so the model doesn't get confused with all 1 class then the other.\n","  \n","  X = []\n","  y = []\n","  \n","  for seq, target in sequential_data:  # going over our new sequential data\n","      X.append(seq)  # X is the sequences\n","      y.append(target)  # y is the targets/labels (buys vs sell/notbuy)\n"," \n","  return np.array(X), y  # return X and y...and make X a numpy array!"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZlektKyHufsV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260300514,"user_tz":-210,"elapsed":283986,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"0679b74b-8378-4928-8d83-9873c63f2c07"},"source":["train_x, train_y = preprocess_df(main_df)\n","validation_x, validation_y = preprocess_df(validation_main_df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"AaRgvOdIAogB"},"source":["last_data=init_df_x.tail(SEQ_LEN)\n","last_data2=last_data.drop(['MID'], axis=1)\n","\n","sequential_data = []  # this is a list that will CONTAIN the sequences\n","prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n","\n","for i in last_data2.values:  # iterate over the values\n","    prev_days.append([n for n in i[:-1]])  # store all but the target\n","    if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n","        sequential_data.append([np.array(prev_days), i[-1]])\n","\n","# Extract your training data\n","X_LAST_init = np.asarray(last_data2)\n","# Use hstack to and reshape to make the inputs a 3d vector\n","X_LSAT = np.hstack(X_LAST_init).reshape(1,SEQ_LEN,last_data2.shape[1])\n","#print(X_LSAT.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AVVpgT1Gufsa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260301184,"user_tz":-210,"elapsed":284646,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"aa55ed30-d59c-4623-8126-83afa0469e4a"},"source":["print(train_x.shape)\n","print(validation_x.shape)\n","print(X_LSAT.shape)\n","\n","print(train_y)\n","print(validation_y)\n","print(last_data)\n","\n","print(train_x.shape[2])\n","print(train_x[:,0,:])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(132, 10, 85)\n","(15, 10, 85)\n","(1, 10, 85)\n","[4.0, 3.0, 1.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 4.0, 4.0, 1.0, 1.0, 1.0, 4.0, 4.0, 4.0, 1.0, 1.0, 4.0, 1.0, 4.0, 2.0, 4.0, 3.0, 4.0, 1.0, 4.0, 3.0, 4.0, 2.0, 4.0, 4.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 1.0, 4.0, 4.0, 1.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 4.0, 1.0, 3.0, 1.0, 1.0, 4.0, 1.0, 1.0, 2.0, 3.0, 2.0, 4.0, 4.0, 4.0, 1.0, 4.0, 1.0, 3.0, 1.0, 4.0, 4.0, 1.0, 4.0, 4.0, 1.0, 3.0, 3.0, 1.0, 2.0, 4.0, 4.0, 4.0, 1.0, 4.0, 4.0, 4.0, 4.0, 1.0, 4.0, 4.0, 1.0, 4.0, 4.0, 4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 4.0, 4.0, 1.0, 4.0, 1.0, 3.0, 4.0, 4.0, 4.0, 1.0, 1.0, 4.0, 3.0, 2.0, 3.0, 3.0, 1.0, 1.0, 1.0]\n","[1.0, 4.0, 4.0, 4.0, 1.0, 4.0, 1.0, 1.0, 1.0, 4.0, 4.0, 2.0, 3.0, 1.0, 4.0]\n","                SHAKHES   VOL-SHAKHES  ...     <LOW>    <CLOSE>\n","<DTYYYYMMDD>                           ...                     \n","2020-06-28    14.166898  8.472173e+09  ...   72988.0   73444.95\n","2020-07-05    14.263224  9.834233e+09  ...   69584.0   80850.00\n","2020-07-12    14.385922  1.116177e+10  ...   83000.0   92120.00\n","2020-07-19    14.423346  1.062910e+10  ...   96720.0  106770.00\n","2020-07-26    14.472507  7.796844e+09  ...  107000.0  127680.00\n","2020-08-02    14.487772  1.060202e+10  ...  112180.0  117380.00\n","2020-08-09    14.521065  9.076221e+09  ...  108300.0  112850.00\n","2020-08-16    14.468707  6.312196e+09  ...   95500.0   98420.00\n","2020-08-23    14.378847  8.468331e+09  ...   86190.0   90330.00\n","2020-08-30    14.321419  7.199384e+09  ...   84030.0   89170.00\n","\n","[10 rows x 86 columns]\n","85\n","[[-0.40692042 -1.25008691 -1.67179977 ... -0.19166753 -0.85619207\n","  -0.53693036]\n"," [-0.16038618 -0.77077044 -0.29546477 ... -0.14759038 -0.25611843\n","  -0.65345055]\n"," [-0.57930162  0.03670451  0.04545377 ...  0.43440092  0.46348125\n","   0.94499042]\n"," ...\n"," [-0.67464121 -0.65533035 -0.49405529 ...  0.90555536  0.65735733\n","   0.69113109]\n"," [-1.00683146  0.03296793  0.47768946 ... -0.15088574 -0.06405236\n","   1.17066985]\n"," [-0.10648456 -0.56799672 -0.5701408  ...  0.96764655  0.8601205\n","   0.66556845]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8-QOQTzzufsd"},"source":["EPOCHS = 100  # how many passes through our data\n","BATCH_SIZE = 32  # how many batches? Try smaller batch if you're getting OOM (out of memory) errors."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R7MOGzgSIslc"},"source":["# **LSTM MODEL**"]},{"cell_type":"code","metadata":{"id":"BIv_J9Oxufsn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260302959,"user_tz":-210,"elapsed":286411,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"6c8b4719-7351-48e7-8fbf-b1e5b522dcb4"},"source":["model = Sequential()\n","model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n"," \n","model.add(LSTM(128, return_sequences=True))\n","model.add(Dropout(0.1))\n","model.add(BatchNormalization())\n","\n","model.add(LSTM(128))\n","model.add(Dropout(0.2))\n","model.add(BatchNormalization())\n"," \n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(0.2))\n","\n","model.add(Dense(3, activation='softmax'))\n","\n","\n","opt = tf.keras.optimizers.Adam(lr=0.005, decay=1e-6)\n"," \n","# Compile model\n","model.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=opt,\n","    metrics=['accuracy'])\n","#model.compile(optimizer='adam', loss='mse')\n","print(model.summary())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm (LSTM)                  (None, 10, 128)           109568    \n","_________________________________________________________________\n","dropout (Dropout)            (None, 10, 128)           0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 10, 128)           512       \n","_________________________________________________________________\n","lstm_1 (LSTM)                (None, 10, 128)           131584    \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 10, 128)           0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 10, 128)           512       \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 128)               131584    \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 128)               0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 128)               512       \n","_________________________________________________________________\n","dense (Dense)                (None, 64)                8256      \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 5)                 325       \n","=================================================================\n","Total params: 382,853\n","Trainable params: 382,085\n","Non-trainable params: 768\n","_________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HyRpt6DOufsu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260319201,"user_tz":-210,"elapsed":302649,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"e8e75b04-2049-43b0-ede1-bf68105795f9"},"source":["# Train model\n"," \n","earlystopping = callbacks.EarlyStopping(monitor =\"val_accuracy\",  \n","                                        mode =\"auto\", patience = 20,\n","                                        restore_best_weights = True) \n","  \n","\n","history = model.fit(train_x, np.array(train_y),\n","    batch_size=BATCH_SIZE,\n","    epochs=EPOCHS,\n","    validation_data=(validation_x, np.array(validation_y)),callbacks =[earlystopping])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","5/5 [==============================] - 7s 449ms/step - loss: 2.1344 - accuracy: 0.1757 - val_loss: 1.5130 - val_accuracy: 0.3333\n","Epoch 2/100\n","5/5 [==============================] - 0s 51ms/step - loss: 1.4506 - accuracy: 0.4834 - val_loss: 1.2269 - val_accuracy: 0.6667\n","Epoch 3/100\n","5/5 [==============================] - 0s 55ms/step - loss: 1.4150 - accuracy: 0.3985 - val_loss: 1.2364 - val_accuracy: 0.6000\n","Epoch 4/100\n","5/5 [==============================] - 0s 56ms/step - loss: 1.2096 - accuracy: 0.5282 - val_loss: 1.2324 - val_accuracy: 0.2000\n","Epoch 5/100\n","5/5 [==============================] - 0s 54ms/step - loss: 1.2505 - accuracy: 0.5459 - val_loss: 1.1231 - val_accuracy: 0.6000\n","Epoch 6/100\n","5/5 [==============================] - 0s 54ms/step - loss: 1.2845 - accuracy: 0.5001 - val_loss: 1.1837 - val_accuracy: 0.6667\n","Epoch 7/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.9671 - accuracy: 0.5677 - val_loss: 1.3103 - val_accuracy: 0.3333\n","Epoch 8/100\n","5/5 [==============================] - 0s 47ms/step - loss: 1.1015 - accuracy: 0.5223 - val_loss: 1.3256 - val_accuracy: 0.2000\n","Epoch 9/100\n","5/5 [==============================] - 0s 46ms/step - loss: 1.1130 - accuracy: 0.5399 - val_loss: 1.2854 - val_accuracy: 0.2667\n","Epoch 10/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.9649 - accuracy: 0.6777 - val_loss: 1.1907 - val_accuracy: 0.2667\n","Epoch 11/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.9750 - accuracy: 0.5584 - val_loss: 1.2312 - val_accuracy: 0.2000\n","Epoch 12/100\n","5/5 [==============================] - 0s 46ms/step - loss: 0.9742 - accuracy: 0.5962 - val_loss: 1.2331 - val_accuracy: 0.2667\n","Epoch 13/100\n","5/5 [==============================] - 0s 50ms/step - loss: 0.9708 - accuracy: 0.5726 - val_loss: 1.0338 - val_accuracy: 0.6000\n","Epoch 14/100\n","5/5 [==============================] - 0s 46ms/step - loss: 0.8599 - accuracy: 0.6039 - val_loss: 1.0975 - val_accuracy: 0.4000\n","Epoch 15/100\n","5/5 [==============================] - 0s 51ms/step - loss: 0.8715 - accuracy: 0.6274 - val_loss: 1.1767 - val_accuracy: 0.2667\n","Epoch 16/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.8360 - accuracy: 0.6969 - val_loss: 1.1841 - val_accuracy: 0.2667\n","Epoch 17/100\n","5/5 [==============================] - 0s 49ms/step - loss: 0.8409 - accuracy: 0.6324 - val_loss: 1.2292 - val_accuracy: 0.4000\n","Epoch 18/100\n","5/5 [==============================] - 0s 46ms/step - loss: 0.7784 - accuracy: 0.6984 - val_loss: 1.1200 - val_accuracy: 0.4667\n","Epoch 19/100\n","5/5 [==============================] - 0s 49ms/step - loss: 0.7240 - accuracy: 0.7347 - val_loss: 1.0557 - val_accuracy: 0.4000\n","Epoch 20/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.7744 - accuracy: 0.6612 - val_loss: 1.0280 - val_accuracy: 0.4667\n","Epoch 21/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.7183 - accuracy: 0.6974 - val_loss: 0.8515 - val_accuracy: 0.7333\n","Epoch 22/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.7960 - accuracy: 0.6226 - val_loss: 1.0220 - val_accuracy: 0.7333\n","Epoch 23/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.7759 - accuracy: 0.6705 - val_loss: 1.1956 - val_accuracy: 0.2667\n","Epoch 24/100\n","5/5 [==============================] - 0s 51ms/step - loss: 0.6697 - accuracy: 0.7062 - val_loss: 1.2471 - val_accuracy: 0.4000\n","Epoch 25/100\n","5/5 [==============================] - 0s 87ms/step - loss: 0.7780 - accuracy: 0.6606 - val_loss: 1.1246 - val_accuracy: 0.4667\n","Epoch 26/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.6646 - accuracy: 0.6902 - val_loss: 1.1082 - val_accuracy: 0.5333\n","Epoch 27/100\n","5/5 [==============================] - 0s 53ms/step - loss: 0.6765 - accuracy: 0.7345 - val_loss: 1.1880 - val_accuracy: 0.2000\n","Epoch 28/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.6375 - accuracy: 0.7191 - val_loss: 1.3430 - val_accuracy: 0.3333\n","Epoch 29/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.6203 - accuracy: 0.7270 - val_loss: 1.2724 - val_accuracy: 0.4000\n","Epoch 30/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.4462 - accuracy: 0.7947 - val_loss: 1.4512 - val_accuracy: 0.4000\n","Epoch 31/100\n","5/5 [==============================] - 0s 50ms/step - loss: 0.5851 - accuracy: 0.7841 - val_loss: 1.3036 - val_accuracy: 0.4000\n","Epoch 32/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.4046 - accuracy: 0.8615 - val_loss: 1.1599 - val_accuracy: 0.4000\n","Epoch 33/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.6301 - accuracy: 0.7653 - val_loss: 1.3023 - val_accuracy: 0.5333\n","Epoch 34/100\n","5/5 [==============================] - 0s 50ms/step - loss: 0.5998 - accuracy: 0.7209 - val_loss: 1.1837 - val_accuracy: 0.6667\n","Epoch 35/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.5582 - accuracy: 0.7828 - val_loss: 1.1960 - val_accuracy: 0.5333\n","Epoch 36/100\n","5/5 [==============================] - 0s 50ms/step - loss: 0.6507 - accuracy: 0.7386 - val_loss: 1.0164 - val_accuracy: 0.6667\n","Epoch 37/100\n","5/5 [==============================] - 0s 49ms/step - loss: 0.5132 - accuracy: 0.8164 - val_loss: 0.9964 - val_accuracy: 0.6667\n","Epoch 38/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.4077 - accuracy: 0.8614 - val_loss: 1.0063 - val_accuracy: 0.6667\n","Epoch 39/100\n","5/5 [==============================] - 0s 52ms/step - loss: 0.3841 - accuracy: 0.8302 - val_loss: 1.0647 - val_accuracy: 0.6000\n","Epoch 40/100\n","5/5 [==============================] - 0s 50ms/step - loss: 0.4457 - accuracy: 0.8293 - val_loss: 1.0030 - val_accuracy: 0.6667\n","Epoch 41/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.3375 - accuracy: 0.8927 - val_loss: 1.0732 - val_accuracy: 0.6000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"owuNZIlEufs0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260320340,"user_tz":-210,"elapsed":303785,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"6a309d6d-220d-4115-a0ca-a60a530f31fb"},"source":["# Score model\n","score = model.evaluate(validation_x, np.array(validation_y), verbose=1)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])\n","pred1=model.predict_classes(X_LSAT)\n","print(pred1[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1/1 [==============================] - 0s 23ms/step - loss: 0.8515 - accuracy: 0.7333\n","Test loss: 0.8514589667320251\n","Test accuracy: 0.7333333492279053\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gnaDd7sRI6jQ"},"source":["# **logestic Regression Model & GA**"]},{"cell_type":"code","metadata":{"id":"4QAZmeeQxiM_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260348157,"user_tz":-210,"elapsed":331598,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"102fd064-d28b-4af9-dfcd-70385a540819"},"source":["X_train=train_x[:,0,:]\n","X_test=validation_x[:,0,:]\n","y_train=np.array(train_y)\n","y_test=np.array(validation_y)\n","#training a logistics regression model\n","logmodel = LogisticRegression(max_iter=10000)\n","logmodel.fit(X_train,y_train)\n","predictions = logmodel.predict(X_test)\n","print(\"Accuracy = \"+ str(accuracy_score(y_test,predictions)))\n"," \n","print(X_train)\n","#defining various steps required for the genetic algorithm\n","def initilization_of_population(size,n_feat):\n","    population = []\n","    for i in range(size):\n","        chromosome = np.ones(n_feat,dtype=np.bool)\n","        chromosome[:int(0.5*n_feat)]=False\n","        np.random.shuffle(chromosome)\n","        population.append(chromosome)\n","    return population\n","\n","def fitness_score(population):\n","    scores = []\n","    for chromosome in population:\n","        logmodel.fit(X_train[:,chromosome],y_train)\n","        predictions = logmodel.predict(X_test[:,chromosome])\n","        scores.append(accuracy_score(y_test,predictions))\n","    scores, population = np.array(scores), np.array(population) \n","    inds = np.argsort(scores)\n","    return list(scores[inds][::-1]), list(population[inds,:][::-1])\n","\n","def selection(pop_after_fit,n_parents):\n","    population_nextgen = []\n","    for i in range(n_parents):\n","        population_nextgen.append(pop_after_fit[i])\n","    return population_nextgen\n","\n","def crossover(pop_after_sel):\n","    population_nextgen=pop_after_sel\n","    for i in range(len(pop_after_sel)):\n","        child=pop_after_sel[i]\n","        child[3:9]=pop_after_sel[(i+1)%len(pop_after_sel)][3:9]\n","        population_nextgen.append(child)\n","    return population_nextgen\n","\n","def mutation(pop_after_cross,mutation_rate):\n","    population_nextgen = []\n","    for i in range(0,len(pop_after_cross)):\n","        chromosome = pop_after_cross[i]\n","        for j in range(len(chromosome)):\n","            if random.random() < mutation_rate:\n","                chromosome[j]= not chromosome[j]\n","        population_nextgen.append(chromosome)\n","    #print(population_nextgen)\n","    return population_nextgen\n","\n","def generations(size,n_feat,n_parents,mutation_rate,n_gen,X_train,X_test, y_train, y_test):\n","    best_chromo= []\n","    best_score= []\n","    population_nextgen=initilization_of_population(size,n_feat)\n","    for i in range(n_gen):\n","        scores, pop_after_fit = fitness_score(population_nextgen)\n","        print(scores[:2])\n","        pop_after_sel = selection(pop_after_fit,n_parents)\n","        pop_after_cross = crossover(pop_after_sel)\n","        population_nextgen = mutation(pop_after_cross,mutation_rate)\n","        best_chromo.append(pop_after_fit[0])\n","        best_score.append(scores[0])\n","    return best_chromo,best_score\n","\n","\n","chromo,score=generations(size=50,n_feat=train_x.shape[2],n_parents=30,mutation_rate=0.02,\n","                     n_gen=20,X_train=X_train,X_test=X_test,y_train=y_train,y_test=y_test)\n","logmodel.fit(X_train[:,chromo[-1]],y_train)\n","predictions = logmodel.predict(X_test[:,chromo[-1]])\n","print(\"Accuracy score after genetic algorithm is= \"+str(accuracy_score(y_test,predictions)))\n","print(chromo[-1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy = 0.4666666666666667\n","[[-0.40692042 -1.25008691 -1.67179977 ... -0.19166753 -0.85619207\n","  -0.53693036]\n"," [-0.16038618 -0.77077044 -0.29546477 ... -0.14759038 -0.25611843\n","  -0.65345055]\n"," [-0.57930162  0.03670451  0.04545377 ...  0.43440092  0.46348125\n","   0.94499042]\n"," ...\n"," [-0.67464121 -0.65533035 -0.49405529 ...  0.90555536  0.65735733\n","   0.69113109]\n"," [-1.00683146  0.03296793  0.47768946 ... -0.15088574 -0.06405236\n","   1.17066985]\n"," [-0.10648456 -0.56799672 -0.5701408  ...  0.96764655  0.8601205\n","   0.66556845]]\n","[0.6, 0.6]\n","[0.6, 0.6]\n","[0.6666666666666666, 0.6666666666666666]\n","[0.6, 0.6]\n","[0.6, 0.6]\n","[0.6666666666666666, 0.6666666666666666]\n","[0.6666666666666666, 0.6666666666666666]\n","[0.6666666666666666, 0.6666666666666666]\n","[0.6666666666666666, 0.6666666666666666]\n","[0.6666666666666666, 0.6666666666666666]\n","[0.6666666666666666, 0.6666666666666666]\n","[0.6666666666666666, 0.6666666666666666]\n","[0.7333333333333333, 0.7333333333333333]\n","[0.6666666666666666, 0.6666666666666666]\n","[0.7333333333333333, 0.7333333333333333]\n","[0.7333333333333333, 0.7333333333333333]\n","[0.7333333333333333, 0.7333333333333333]\n","[0.7333333333333333, 0.7333333333333333]\n","[0.8, 0.8]\n","[0.7333333333333333, 0.7333333333333333]\n","Accuracy score after genetic algorithm is= 0.7333333333333333\n","[ True  True  True  True  True  True  True  True False  True False False\n"," False False False  True False False  True False False False  True False\n"," False  True  True  True False  True  True False  True False False  True\n","  True False  True  True False  True  True  True  True False  True  True\n"," False False False  True False  True False False  True False  True False\n","  True False False  True  True  True False False False False  True False\n","  True  True False False False False  True False False False  True  True\n"," False]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kw6mBYvcJE-0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260348159,"user_tz":-210,"elapsed":331595,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"27029772-2e13-48d1-edfc-f9f19a66c5d2"},"source":["best_chromosome=[i for i, x in enumerate(chromo[-1]) if x]\n","train_x2=train_x[:,:,best_chromosome]\n","validation_x2=validation_x[:,:,best_chromosome]\n","print(train_x2.shape[1:])\n","print(train_x2.shape)\n","print(validation_x2.shape)\n","print(best_chromosome)\n","\n","\n","pred33=logmodel.predict(X_LSAT[:,0,best_chromosome])\n","print(pred33[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(10, 42)\n","(132, 10, 42)\n","(15, 10, 42)\n","[0, 1, 2, 3, 4, 5, 6, 7, 9, 15, 18, 22, 25, 26, 27, 29, 30, 32, 35, 36, 38, 39, 41, 42, 43, 44, 46, 47, 51, 53, 56, 58, 60, 63, 64, 65, 70, 72, 73, 78, 82, 83]\n","3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IKgdje9COsY0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260371468,"user_tz":-210,"elapsed":354899,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"10e667ea-cd6e-4800-804c-330c999f57da"},"source":["model2 = Sequential()\n","model2.add(LSTM(256, input_shape=(train_x2.shape[1:]), return_sequences=True))\n","model2.add(Dropout(0.2))\n","model2.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n"," \n","model2.add(LSTM(128, return_sequences=True))\n","model2.add(Dropout(0.1))\n","model2.add(BatchNormalization())\n","\n","model2.add(LSTM(128))\n","model2.add(Dropout(0.2))\n","model2.add(BatchNormalization())\n"," \n","model2.add(Dense(64, activation='relu'))\n","model2.add(Dropout(0.2))\n","\n","model2.add(Dense(5, activation='softmax'))\n","\n","\n","opt = tf.keras.optimizers.Adam(lr=0.05, decay=1e-6)\n"," \n","# Compile model\n","model2.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=opt,\n","    metrics=['accuracy'])\n","#model.compile(optimizer='adam', loss='mse')\n","#print(model2.summary())\n","\n","\n","earlystopping_model2 = callbacks.EarlyStopping(monitor =\"val_loss\", mode =\"auto\", patience = 30,restore_best_weights = True) \n","history = model2.fit(train_x2, np.array(train_y),batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=(validation_x2, np.array(validation_y)),callbacks =[earlystopping_model2])\n","\n","score2 = model2.evaluate(validation_x2, np.array(validation_y), verbose=1)\n","print('Test loss:', score2[0])\n","print('Test accuracy:', score2[1])\n","pred3=model2.predict_classes(X_LSAT[:,:,best_chromosome])\n","print(pred3[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","5/5 [==============================] - 7s 374ms/step - loss: 2.5739 - accuracy: 0.3447 - val_loss: 1.5767 - val_accuracy: 0.6667\n","Epoch 2/100\n","5/5 [==============================] - 0s 92ms/step - loss: 2.3018 - accuracy: 0.3905 - val_loss: 1.3008 - val_accuracy: 0.2667\n","Epoch 3/100\n","5/5 [==============================] - 0s 86ms/step - loss: 1.5418 - accuracy: 0.3670 - val_loss: 1.1800 - val_accuracy: 0.4667\n","Epoch 4/100\n","5/5 [==============================] - 0s 86ms/step - loss: 1.3345 - accuracy: 0.3864 - val_loss: 0.9474 - val_accuracy: 0.5333\n","Epoch 5/100\n","5/5 [==============================] - 0s 94ms/step - loss: 1.4319 - accuracy: 0.3492 - val_loss: 1.3688 - val_accuracy: 0.0667\n","Epoch 6/100\n","5/5 [==============================] - 0s 84ms/step - loss: 1.4536 - accuracy: 0.4001 - val_loss: 1.2719 - val_accuracy: 0.4667\n","Epoch 7/100\n","5/5 [==============================] - 0s 90ms/step - loss: 1.3260 - accuracy: 0.4199 - val_loss: 1.1877 - val_accuracy: 0.4667\n","Epoch 8/100\n","5/5 [==============================] - 0s 86ms/step - loss: 1.3601 - accuracy: 0.4341 - val_loss: 1.3779 - val_accuracy: 0.4000\n","Epoch 9/100\n","5/5 [==============================] - 0s 88ms/step - loss: 1.2557 - accuracy: 0.4424 - val_loss: 1.1515 - val_accuracy: 0.4667\n","Epoch 10/100\n","5/5 [==============================] - 0s 93ms/step - loss: 1.3328 - accuracy: 0.3817 - val_loss: 1.2742 - val_accuracy: 0.4667\n","Epoch 11/100\n","5/5 [==============================] - 0s 86ms/step - loss: 1.2897 - accuracy: 0.3978 - val_loss: 1.3186 - val_accuracy: 0.0667\n","Epoch 12/100\n","5/5 [==============================] - 0s 84ms/step - loss: 1.2259 - accuracy: 0.4465 - val_loss: 1.2020 - val_accuracy: 0.3333\n","Epoch 13/100\n","5/5 [==============================] - 0s 85ms/step - loss: 1.3171 - accuracy: 0.4158 - val_loss: 1.2478 - val_accuracy: 0.1333\n","Epoch 14/100\n","5/5 [==============================] - 0s 86ms/step - loss: 1.2200 - accuracy: 0.4698 - val_loss: 1.2128 - val_accuracy: 0.2000\n","Epoch 15/100\n","5/5 [==============================] - 0s 89ms/step - loss: 1.1655 - accuracy: 0.5171 - val_loss: 1.2284 - val_accuracy: 0.2000\n","Epoch 16/100\n","5/5 [==============================] - 0s 90ms/step - loss: 1.2015 - accuracy: 0.4892 - val_loss: 1.2041 - val_accuracy: 0.4667\n","Epoch 17/100\n","5/5 [==============================] - 0s 83ms/step - loss: 1.3041 - accuracy: 0.4200 - val_loss: 1.1661 - val_accuracy: 0.6667\n","Epoch 18/100\n","5/5 [==============================] - 0s 78ms/step - loss: 1.2230 - accuracy: 0.4569 - val_loss: 1.1848 - val_accuracy: 0.3333\n","Epoch 19/100\n","5/5 [==============================] - 0s 78ms/step - loss: 1.1772 - accuracy: 0.4699 - val_loss: 1.1759 - val_accuracy: 0.4667\n","Epoch 20/100\n","5/5 [==============================] - 0s 85ms/step - loss: 1.1403 - accuracy: 0.5144 - val_loss: 1.1720 - val_accuracy: 0.3333\n","Epoch 21/100\n","5/5 [==============================] - 0s 88ms/step - loss: 1.1345 - accuracy: 0.4966 - val_loss: 1.1963 - val_accuracy: 0.3333\n","Epoch 22/100\n","5/5 [==============================] - 0s 86ms/step - loss: 1.1707 - accuracy: 0.4769 - val_loss: 1.3869 - val_accuracy: 0.2000\n","Epoch 23/100\n","5/5 [==============================] - 0s 84ms/step - loss: 1.2080 - accuracy: 0.4910 - val_loss: 1.2543 - val_accuracy: 0.2000\n","Epoch 24/100\n","5/5 [==============================] - 1s 157ms/step - loss: 1.1813 - accuracy: 0.4671 - val_loss: 1.2589 - val_accuracy: 0.3333\n","Epoch 25/100\n","5/5 [==============================] - 0s 88ms/step - loss: 1.1726 - accuracy: 0.4658 - val_loss: 1.2101 - val_accuracy: 0.4000\n","Epoch 26/100\n","5/5 [==============================] - 0s 82ms/step - loss: 1.2077 - accuracy: 0.4955 - val_loss: 1.1744 - val_accuracy: 0.4000\n","Epoch 27/100\n","5/5 [==============================] - 0s 75ms/step - loss: 1.2115 - accuracy: 0.4582 - val_loss: 1.1836 - val_accuracy: 0.4000\n","Epoch 28/100\n","5/5 [==============================] - 0s 80ms/step - loss: 1.2441 - accuracy: 0.3974 - val_loss: 1.1719 - val_accuracy: 0.4000\n","Epoch 29/100\n","5/5 [==============================] - 0s 78ms/step - loss: 1.2116 - accuracy: 0.4240 - val_loss: 1.1530 - val_accuracy: 0.4000\n","Epoch 30/100\n","5/5 [==============================] - 0s 76ms/step - loss: 1.2559 - accuracy: 0.4349 - val_loss: 1.1378 - val_accuracy: 0.4000\n","Epoch 31/100\n","5/5 [==============================] - 0s 82ms/step - loss: 1.1867 - accuracy: 0.3720 - val_loss: 1.1347 - val_accuracy: 0.4667\n","Epoch 32/100\n","5/5 [==============================] - 0s 77ms/step - loss: 1.2556 - accuracy: 0.4622 - val_loss: 1.1377 - val_accuracy: 0.4667\n","Epoch 33/100\n","5/5 [==============================] - 0s 78ms/step - loss: 1.1936 - accuracy: 0.3805 - val_loss: 1.1450 - val_accuracy: 0.4000\n","Epoch 34/100\n","5/5 [==============================] - 0s 81ms/step - loss: 1.2175 - accuracy: 0.4235 - val_loss: 1.1805 - val_accuracy: 0.2667\n","1/1 [==============================] - 0s 30ms/step - loss: 0.9474 - accuracy: 0.5333\n","Test loss: 0.9474366307258606\n","Test accuracy: 0.5333333611488342\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yv6rNQK5JgTV"},"source":["# **LSTM & GA**"]},{"cell_type":"code","metadata":{"id":"NhVqtAymLNrL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260455400,"user_tz":-210,"elapsed":438828,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"744777a2-e71d-4a72-e49c-6bbd1339ae92"},"source":["def logmodel(chromosome):\n","  global logmodel\n","  logmodel = Sequential()\n","  logmodel.add(LSTM(128, input_shape=(X_train[:,:,chromosome].shape[1:]), return_sequences=True))\n","  logmodel.add(Dropout(0.2))\n","  logmodel.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n"," \n","  logmodel.add(LSTM(128, return_sequences=True))\n","  logmodel.add(Dropout(0.1))\n","  logmodel.add(BatchNormalization())\n"," \n","  logmodel.add(LSTM(128))\n","  logmodel.add(Dropout(0.2))\n","  logmodel.add(BatchNormalization())\n"," \n","  logmodel.add(Dense(64, activation='relu'))\n","  logmodel.add(Dropout(0.2))\n"," \n"," \n"," \n","  logmodel.add(Dense(5, activation='softmax'))\n","  opt = tf.keras.optimizers.Adam(lr=0.005, decay=1e-6)\n"," \n","  # Compile model\n","  logmodel.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=opt,\n","    metrics=['accuracy'])\n","  #model.compile(optimizer='adam', loss='mse')\n","  print(logmodel.summary())\n","\n","\n","size=10\n","X_train=train_x\n","X_test=validation_x\n","y_train=train_y\n","y_test=validation_y\n","chromosome =list(np.random.choice((main_df.shape[1]-3),size))\n","logmodel(chromosome)\n","\n","\n","#defining various steps required for the genetic algorithm\n","\n","def initilization_of_population(size):\n","    population = []\n","    for i in range(size):\n","        chromosome =list(np.random.choice(range(main_df.shape[1]-3), size, replace=False))\n","        #chromosome =list(np.random.choice((main_df.shape[1]-3),size))\n","        #np.random.shuffle(chromosome)\n","        population.append(chromosome)\n","        #print(population)\n","        print(chromosome)\n","    return population\n","\n","def fitness_score(population):\n","    scores = []\n","    for chromosome in population:\n","        logmodel.fit(X_train[:,:,chromosome],np.array(y_train),batch_size=BATCH_SIZE,epochs=25,validation_data=(X_test[:,:,chromosome], np.array(y_test)),callbacks =[earlystopping])\n","        predictions = logmodel.predict_classes(X_test[:,:,chromosome])\n","        scores.append(accuracy_score(y_test,predictions))\n","    scores, population = np.array(scores), np.array(population) \n","    inds = np.argsort(scores)\n","    return list(scores[inds][::-1]), list(population[inds,:][::-1])\n","    print(list(scores[inds][::-1]), list(population[inds,:][::-1]))\n","def selection(pop_after_fit,n_parents):\n","    population_nextgen = []\n","    for i in range(n_parents):\n","        population_nextgen.append(pop_after_fit[i])\n","    return population_nextgen\n","\n","def crossover(pop_after_sel):\n","    population_nextgen=pop_after_sel\n","    for i in range(len(pop_after_sel)):\n","        child=pop_after_sel[i]\n","        child[2:8]=pop_after_sel[(i+1)%len(pop_after_sel)][2:8]\n","        population_nextgen.append(child)\n","    return population_nextgen\n","\n","def mutation(pop_after_cross,mutation_rate):\n","    population_nextgen = []\n","    for i in range(0,len(pop_after_cross)):\n","        chromosome = pop_after_cross[i]\n","        for j in range(len(chromosome)):\n","            if random.random() < mutation_rate:\n","                chromosome[j]= not chromosome[j]\n","        population_nextgen.append(chromosome)\n","    return population_nextgen\n","\n","def generations(size,n_parents,mutation_rate,n_gen,X_train,X_test, y_train, y_test):\n","    best_chromo= []\n","    best_score= []\n","    population_nextgen=initilization_of_population(size)\n","    for i in range(n_gen):\n","        scores,pop_after_fit = fitness_score(population_nextgen)\n","        print(scores[:2])\n","        pop_after_sel = selection(pop_after_fit,n_parents)\n","        pop_after_cross = crossover(pop_after_sel)\n","        population_nextgen = mutation(pop_after_cross,mutation_rate)\n","        best_chromo.append(pop_after_fit[0])\n","        best_score.append(scores[0])\n","    return best_chromo,best_score\n","\n","\n","\n","\n","chromo,score = generations(size=size,n_parents=1,mutation_rate=0.02,n_gen=1,X_train=train_x, X_test=validation_x, y_train=train_y, y_test=validation_y)\n","\n","predlstmga=logmodel.predict_classes(X_LSAT[:,:,chromo[-1]])\n","print(predlstmga[0])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_6 (LSTM)                (None, 10, 128)           71168     \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 10, 128)           0         \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 10, 128)           512       \n","_________________________________________________________________\n","lstm_7 (LSTM)                (None, 10, 128)           131584    \n","_________________________________________________________________\n","dropout_9 (Dropout)          (None, 10, 128)           0         \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 10, 128)           512       \n","_________________________________________________________________\n","lstm_8 (LSTM)                (None, 128)               131584    \n","_________________________________________________________________\n","dropout_10 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 128)               512       \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 64)                8256      \n","_________________________________________________________________\n","dropout_11 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 5)                 325       \n","=================================================================\n","Total params: 344,453\n","Trainable params: 343,685\n","Non-trainable params: 768\n","_________________________________________________________________\n","None\n","[65, 12, 83, 4, 52, 34, 16, 57, 27, 0]\n","[12, 43, 51, 62, 37, 57, 41, 64, 82, 68]\n","[0, 1, 2, 17, 73, 16, 84, 72, 53, 68]\n","[73, 65, 66, 8, 78, 74, 80, 23, 40, 28]\n","[62, 49, 80, 43, 70, 57, 64, 76, 34, 55]\n","[65, 21, 57, 3, 13, 1, 80, 59, 71, 54]\n","[21, 35, 4, 12, 9, 64, 16, 55, 23, 51]\n","[57, 25, 63, 21, 84, 32, 60, 70, 43, 26]\n","[2, 52, 59, 48, 74, 57, 39, 19, 14, 7]\n","[31, 8, 30, 39, 10, 60, 4, 65, 29, 79]\n","Epoch 1/25\n","5/5 [==============================] - 7s 353ms/step - loss: 2.1267 - accuracy: 0.2187 - val_loss: 1.4823 - val_accuracy: 0.4000\n","Epoch 2/25\n","5/5 [==============================] - 0s 57ms/step - loss: 1.4533 - accuracy: 0.5154 - val_loss: 1.3315 - val_accuracy: 0.5333\n","Epoch 3/25\n","5/5 [==============================] - 0s 54ms/step - loss: 1.3281 - accuracy: 0.4996 - val_loss: 1.2426 - val_accuracy: 0.4667\n","Epoch 4/25\n","5/5 [==============================] - 0s 54ms/step - loss: 1.4845 - accuracy: 0.4703 - val_loss: 1.2302 - val_accuracy: 0.5333\n","Epoch 5/25\n","5/5 [==============================] - 0s 55ms/step - loss: 1.1034 - accuracy: 0.5148 - val_loss: 1.2699 - val_accuracy: 0.3333\n","Epoch 6/25\n","5/5 [==============================] - 0s 57ms/step - loss: 1.1101 - accuracy: 0.5380 - val_loss: 1.2739 - val_accuracy: 0.2667\n","Epoch 7/25\n","5/5 [==============================] - 0s 52ms/step - loss: 1.0040 - accuracy: 0.5760 - val_loss: 1.1955 - val_accuracy: 0.5333\n","Epoch 8/25\n","5/5 [==============================] - 0s 64ms/step - loss: 1.1999 - accuracy: 0.4834 - val_loss: 1.2260 - val_accuracy: 0.4000\n","Epoch 9/25\n","5/5 [==============================] - 0s 65ms/step - loss: 1.0881 - accuracy: 0.5403 - val_loss: 1.2504 - val_accuracy: 0.4667\n","Epoch 10/25\n","5/5 [==============================] - 0s 65ms/step - loss: 0.9483 - accuracy: 0.5618 - val_loss: 1.1272 - val_accuracy: 0.7333\n","Epoch 11/25\n","5/5 [==============================] - 0s 58ms/step - loss: 0.9710 - accuracy: 0.6168 - val_loss: 1.0895 - val_accuracy: 0.7333\n","Epoch 12/25\n","5/5 [==============================] - 0s 54ms/step - loss: 0.9832 - accuracy: 0.5700 - val_loss: 1.1668 - val_accuracy: 0.8000\n","Epoch 13/25\n","5/5 [==============================] - 0s 57ms/step - loss: 0.9881 - accuracy: 0.5894 - val_loss: 1.2115 - val_accuracy: 0.7333\n","Epoch 14/25\n","5/5 [==============================] - 0s 56ms/step - loss: 0.9536 - accuracy: 0.6046 - val_loss: 1.2287 - val_accuracy: 0.7333\n","Epoch 15/25\n","5/5 [==============================] - 1s 146ms/step - loss: 0.8579 - accuracy: 0.6564 - val_loss: 1.2369 - val_accuracy: 0.6000\n","Epoch 16/25\n","5/5 [==============================] - 0s 64ms/step - loss: 0.9405 - accuracy: 0.5843 - val_loss: 1.2018 - val_accuracy: 0.6000\n","Epoch 17/25\n","5/5 [==============================] - 0s 61ms/step - loss: 0.7035 - accuracy: 0.7308 - val_loss: 1.2904 - val_accuracy: 0.4667\n","Epoch 18/25\n","5/5 [==============================] - 0s 56ms/step - loss: 0.8694 - accuracy: 0.6527 - val_loss: 1.3743 - val_accuracy: 0.6000\n","Epoch 19/25\n","5/5 [==============================] - 0s 56ms/step - loss: 0.8621 - accuracy: 0.6009 - val_loss: 1.5014 - val_accuracy: 0.4000\n","Epoch 20/25\n","5/5 [==============================] - 0s 52ms/step - loss: 0.9190 - accuracy: 0.6055 - val_loss: 1.6083 - val_accuracy: 0.2667\n","Epoch 21/25\n","5/5 [==============================] - 0s 59ms/step - loss: 0.9512 - accuracy: 0.5218 - val_loss: 1.6085 - val_accuracy: 0.5333\n","Epoch 22/25\n","5/5 [==============================] - 0s 64ms/step - loss: 0.9362 - accuracy: 0.6156 - val_loss: 1.5178 - val_accuracy: 0.6667\n","Epoch 23/25\n","5/5 [==============================] - 0s 67ms/step - loss: 0.7305 - accuracy: 0.6861 - val_loss: 1.4633 - val_accuracy: 0.6000\n","Epoch 24/25\n","5/5 [==============================] - 0s 64ms/step - loss: 0.9081 - accuracy: 0.6235 - val_loss: 1.5010 - val_accuracy: 0.4000\n","Epoch 25/25\n","5/5 [==============================] - 0s 52ms/step - loss: 0.8760 - accuracy: 0.6014 - val_loss: 1.4835 - val_accuracy: 0.4667\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/25\n","5/5 [==============================] - 0s 69ms/step - loss: 1.6954 - accuracy: 0.3939 - val_loss: 1.6762 - val_accuracy: 0.1333\n","Epoch 2/25\n","5/5 [==============================] - 0s 52ms/step - loss: 1.2780 - accuracy: 0.4621 - val_loss: 1.9821 - val_accuracy: 0.1333\n","Epoch 3/25\n","5/5 [==============================] - 1s 149ms/step - loss: 1.1214 - accuracy: 0.4924 - val_loss: 1.7231 - val_accuracy: 0.1333\n","Epoch 4/25\n","5/5 [==============================] - 0s 63ms/step - loss: 1.1033 - accuracy: 0.4470 - val_loss: 1.1816 - val_accuracy: 0.4667\n","Epoch 5/25\n","5/5 [==============================] - 0s 67ms/step - loss: 1.0669 - accuracy: 0.5152 - val_loss: 1.1926 - val_accuracy: 0.4000\n","Epoch 6/25\n","5/5 [==============================] - 0s 76ms/step - loss: 1.0789 - accuracy: 0.5530 - val_loss: 1.3094 - val_accuracy: 0.3333\n","Epoch 7/25\n","5/5 [==============================] - 0s 63ms/step - loss: 0.9443 - accuracy: 0.6136 - val_loss: 1.2509 - val_accuracy: 0.4667\n","Epoch 8/25\n","5/5 [==============================] - 0s 64ms/step - loss: 0.9240 - accuracy: 0.5909 - val_loss: 1.1348 - val_accuracy: 0.4000\n","Epoch 9/25\n","5/5 [==============================] - 0s 62ms/step - loss: 0.9775 - accuracy: 0.5530 - val_loss: 1.1147 - val_accuracy: 0.4000\n","Epoch 10/25\n","5/5 [==============================] - 0s 66ms/step - loss: 0.8562 - accuracy: 0.6288 - val_loss: 1.3678 - val_accuracy: 0.1333\n","Epoch 11/25\n","5/5 [==============================] - 0s 62ms/step - loss: 0.8102 - accuracy: 0.6742 - val_loss: 1.4580 - val_accuracy: 0.1333\n","Epoch 12/25\n","5/5 [==============================] - 0s 54ms/step - loss: 0.8964 - accuracy: 0.6364 - val_loss: 1.3190 - val_accuracy: 0.4667\n","Epoch 13/25\n","5/5 [==============================] - 0s 55ms/step - loss: 0.8626 - accuracy: 0.6439 - val_loss: 1.2135 - val_accuracy: 0.4667\n","Epoch 14/25\n","5/5 [==============================] - 0s 50ms/step - loss: 0.9153 - accuracy: 0.5758 - val_loss: 1.2753 - val_accuracy: 0.4667\n","Epoch 15/25\n","5/5 [==============================] - 0s 54ms/step - loss: 0.9238 - accuracy: 0.5455 - val_loss: 1.2257 - val_accuracy: 0.4667\n","Epoch 16/25\n","5/5 [==============================] - 0s 63ms/step - loss: 0.9146 - accuracy: 0.6136 - val_loss: 1.1601 - val_accuracy: 0.5333\n","Epoch 17/25\n","5/5 [==============================] - 0s 63ms/step - loss: 0.8536 - accuracy: 0.6212 - val_loss: 1.2592 - val_accuracy: 0.3333\n","Epoch 18/25\n","5/5 [==============================] - 0s 64ms/step - loss: 0.8207 - accuracy: 0.6818 - val_loss: 1.3086 - val_accuracy: 0.2000\n","Epoch 19/25\n","5/5 [==============================] - 0s 62ms/step - loss: 0.6828 - accuracy: 0.7348 - val_loss: 1.3110 - val_accuracy: 0.4000\n","Epoch 20/25\n","5/5 [==============================] - 0s 67ms/step - loss: 0.7109 - accuracy: 0.7348 - val_loss: 1.5097 - val_accuracy: 0.3333\n","Epoch 21/25\n","5/5 [==============================] - 0s 62ms/step - loss: 0.7123 - accuracy: 0.6894 - val_loss: 1.4990 - val_accuracy: 0.4000\n","Epoch 22/25\n","5/5 [==============================] - 0s 62ms/step - loss: 0.7393 - accuracy: 0.6591 - val_loss: 1.1663 - val_accuracy: 0.4667\n","Epoch 23/25\n","5/5 [==============================] - 0s 63ms/step - loss: 0.6383 - accuracy: 0.7500 - val_loss: 1.0317 - val_accuracy: 0.6667\n","Epoch 24/25\n","5/5 [==============================] - 0s 68ms/step - loss: 0.7414 - accuracy: 0.7500 - val_loss: 1.2953 - val_accuracy: 0.4667\n","Epoch 25/25\n","5/5 [==============================] - 0s 62ms/step - loss: 0.8059 - accuracy: 0.6742 - val_loss: 1.3787 - val_accuracy: 0.6000\n","Epoch 1/25\n","5/5 [==============================] - 1s 180ms/step - loss: 1.7182 - accuracy: 0.2955 - val_loss: 1.4006 - val_accuracy: 0.3333\n","Epoch 2/25\n","5/5 [==============================] - 0s 64ms/step - loss: 1.3449 - accuracy: 0.4091 - val_loss: 1.2500 - val_accuracy: 0.4667\n","Epoch 3/25\n","5/5 [==============================] - 0s 65ms/step - loss: 1.2153 - accuracy: 0.3939 - val_loss: 1.1699 - val_accuracy: 0.4667\n","Epoch 4/25\n","5/5 [==============================] - 0s 61ms/step - loss: 1.1571 - accuracy: 0.4621 - val_loss: 1.1569 - val_accuracy: 0.6000\n","Epoch 5/25\n","5/5 [==============================] - 0s 62ms/step - loss: 1.1303 - accuracy: 0.4924 - val_loss: 1.2545 - val_accuracy: 0.4667\n","Epoch 6/25\n","5/5 [==============================] - 0s 54ms/step - loss: 1.1496 - accuracy: 0.4924 - val_loss: 1.3096 - val_accuracy: 0.3333\n","Epoch 7/25\n","5/5 [==============================] - 0s 57ms/step - loss: 1.1019 - accuracy: 0.5152 - val_loss: 1.1366 - val_accuracy: 0.5333\n","Epoch 8/25\n","5/5 [==============================] - 0s 55ms/step - loss: 1.0850 - accuracy: 0.4394 - val_loss: 1.0855 - val_accuracy: 0.5333\n","Epoch 9/25\n","5/5 [==============================] - 0s 53ms/step - loss: 1.1448 - accuracy: 0.4697 - val_loss: 1.1054 - val_accuracy: 0.6667\n","Epoch 10/25\n","5/5 [==============================] - 0s 71ms/step - loss: 1.0714 - accuracy: 0.5000 - val_loss: 1.1710 - val_accuracy: 0.5333\n","Epoch 11/25\n","5/5 [==============================] - 0s 67ms/step - loss: 1.0509 - accuracy: 0.5152 - val_loss: 1.1672 - val_accuracy: 0.6000\n","Epoch 12/25\n","5/5 [==============================] - 0s 66ms/step - loss: 0.9720 - accuracy: 0.5379 - val_loss: 1.2050 - val_accuracy: 0.6667\n","Epoch 13/25\n","5/5 [==============================] - 0s 53ms/step - loss: 0.9648 - accuracy: 0.5303 - val_loss: 1.2931 - val_accuracy: 0.6000\n","Epoch 14/25\n","5/5 [==============================] - 0s 54ms/step - loss: 0.9290 - accuracy: 0.5985 - val_loss: 1.5668 - val_accuracy: 0.5333\n","Epoch 15/25\n","5/5 [==============================] - 0s 56ms/step - loss: 0.9336 - accuracy: 0.5530 - val_loss: 2.0030 - val_accuracy: 0.5333\n","Epoch 16/25\n","5/5 [==============================] - 0s 51ms/step - loss: 0.9024 - accuracy: 0.5530 - val_loss: 2.0383 - val_accuracy: 0.4667\n","Epoch 17/25\n","5/5 [==============================] - 0s 61ms/step - loss: 0.8538 - accuracy: 0.5833 - val_loss: 1.8652 - val_accuracy: 0.4000\n","Epoch 18/25\n","5/5 [==============================] - 0s 70ms/step - loss: 0.8780 - accuracy: 0.6288 - val_loss: 1.4200 - val_accuracy: 0.3333\n","Epoch 19/25\n","5/5 [==============================] - 0s 62ms/step - loss: 0.9034 - accuracy: 0.6515 - val_loss: 1.3010 - val_accuracy: 0.4000\n","Epoch 20/25\n","5/5 [==============================] - 1s 152ms/step - loss: 0.8959 - accuracy: 0.6212 - val_loss: 1.3859 - val_accuracy: 0.4000\n","Epoch 21/25\n","5/5 [==============================] - 0s 63ms/step - loss: 0.9337 - accuracy: 0.5985 - val_loss: 1.5444 - val_accuracy: 0.4000\n","Epoch 22/25\n","5/5 [==============================] - 0s 64ms/step - loss: 0.9566 - accuracy: 0.5833 - val_loss: 1.5060 - val_accuracy: 0.4667\n","Epoch 23/25\n","5/5 [==============================] - 0s 64ms/step - loss: 0.9960 - accuracy: 0.5379 - val_loss: 1.8727 - val_accuracy: 0.4667\n","Epoch 24/25\n","5/5 [==============================] - 0s 64ms/step - loss: 0.8666 - accuracy: 0.6212 - val_loss: 2.3376 - val_accuracy: 0.2000\n","Epoch 25/25\n","5/5 [==============================] - 0s 64ms/step - loss: 0.9678 - accuracy: 0.5455 - val_loss: 2.3847 - val_accuracy: 0.2667\n","Epoch 1/25\n","5/5 [==============================] - 0s 88ms/step - loss: 1.5699 - accuracy: 0.3864 - val_loss: 1.3981 - val_accuracy: 0.2000\n","Epoch 2/25\n","5/5 [==============================] - 0s 59ms/step - loss: 1.2394 - accuracy: 0.4318 - val_loss: 1.5026 - val_accuracy: 0.2000\n","Epoch 3/25\n","5/5 [==============================] - 0s 62ms/step - loss: 1.2408 - accuracy: 0.4242 - val_loss: 1.4656 - val_accuracy: 0.4667\n","Epoch 4/25\n","5/5 [==============================] - 0s 71ms/step - loss: 1.1523 - accuracy: 0.5000 - val_loss: 1.5164 - val_accuracy: 0.3333\n","Epoch 5/25\n","5/5 [==============================] - 0s 63ms/step - loss: 1.1036 - accuracy: 0.5682 - val_loss: 1.4961 - val_accuracy: 0.3333\n","Epoch 6/25\n","5/5 [==============================] - 0s 63ms/step - loss: 1.1170 - accuracy: 0.5379 - val_loss: 1.4535 - val_accuracy: 0.3333\n","Epoch 7/25\n","5/5 [==============================] - 0s 53ms/step - loss: 1.1038 - accuracy: 0.4697 - val_loss: 1.3805 - val_accuracy: 0.4000\n","Epoch 8/25\n","5/5 [==============================] - 0s 56ms/step - loss: 1.0845 - accuracy: 0.5227 - val_loss: 1.5623 - val_accuracy: 0.4000\n","Epoch 9/25\n","5/5 [==============================] - 0s 55ms/step - loss: 1.1831 - accuracy: 0.4621 - val_loss: 1.4651 - val_accuracy: 0.3333\n","Epoch 10/25\n","5/5 [==============================] - 0s 55ms/step - loss: 1.1512 - accuracy: 0.4470 - val_loss: 1.3966 - val_accuracy: 0.3333\n","Epoch 11/25\n","5/5 [==============================] - 0s 66ms/step - loss: 1.0470 - accuracy: 0.5152 - val_loss: 1.6148 - val_accuracy: 0.2000\n","Epoch 12/25\n","5/5 [==============================] - 0s 62ms/step - loss: 1.0534 - accuracy: 0.5152 - val_loss: 1.7007 - val_accuracy: 0.2000\n","Epoch 13/25\n","5/5 [==============================] - 0s 67ms/step - loss: 1.0034 - accuracy: 0.5000 - val_loss: 1.7124 - val_accuracy: 0.3333\n","Epoch 14/25\n","5/5 [==============================] - 0s 55ms/step - loss: 0.9627 - accuracy: 0.5985 - val_loss: 1.5900 - val_accuracy: 0.1333\n","Epoch 15/25\n","5/5 [==============================] - 1s 135ms/step - loss: 0.9554 - accuracy: 0.5833 - val_loss: 1.5099 - val_accuracy: 0.3333\n","Epoch 16/25\n","5/5 [==============================] - 0s 53ms/step - loss: 0.9260 - accuracy: 0.6061 - val_loss: 1.4408 - val_accuracy: 0.4000\n","Epoch 17/25\n","5/5 [==============================] - 0s 63ms/step - loss: 0.9338 - accuracy: 0.5833 - val_loss: 1.3788 - val_accuracy: 0.2667\n","Epoch 18/25\n","5/5 [==============================] - 0s 68ms/step - loss: 0.9287 - accuracy: 0.5455 - val_loss: 1.3629 - val_accuracy: 0.2000\n","Epoch 19/25\n","5/5 [==============================] - 0s 63ms/step - loss: 0.9658 - accuracy: 0.6136 - val_loss: 1.3903 - val_accuracy: 0.2000\n","Epoch 20/25\n","5/5 [==============================] - 0s 65ms/step - loss: 0.8573 - accuracy: 0.6439 - val_loss: 1.4709 - val_accuracy: 0.2667\n","Epoch 21/25\n","5/5 [==============================] - 0s 65ms/step - loss: 0.8717 - accuracy: 0.6061 - val_loss: 1.3940 - val_accuracy: 0.3333\n","Epoch 22/25\n","5/5 [==============================] - 0s 68ms/step - loss: 0.8888 - accuracy: 0.6061 - val_loss: 1.4804 - val_accuracy: 0.4000\n","Epoch 23/25\n","5/5 [==============================] - 0s 64ms/step - loss: 0.8412 - accuracy: 0.6364 - val_loss: 1.7396 - val_accuracy: 0.3333\n","Epoch 1/25\n","5/5 [==============================] - 0s 93ms/step - loss: 1.4168 - accuracy: 0.3182 - val_loss: 1.4032 - val_accuracy: 0.3333\n","Epoch 2/25\n","5/5 [==============================] - 0s 65ms/step - loss: 1.1652 - accuracy: 0.4318 - val_loss: 1.5384 - val_accuracy: 0.3333\n","Epoch 3/25\n","5/5 [==============================] - 0s 70ms/step - loss: 1.0773 - accuracy: 0.5530 - val_loss: 1.7096 - val_accuracy: 0.2667\n","Epoch 4/25\n","5/5 [==============================] - 0s 63ms/step - loss: 1.0841 - accuracy: 0.5606 - val_loss: 1.6487 - val_accuracy: 0.2000\n","Epoch 5/25\n","5/5 [==============================] - 0s 64ms/step - loss: 1.0253 - accuracy: 0.5758 - val_loss: 1.4975 - val_accuracy: 0.2000\n","Epoch 6/25\n","5/5 [==============================] - 0s 69ms/step - loss: 0.9609 - accuracy: 0.5833 - val_loss: 1.3949 - val_accuracy: 0.2000\n","Epoch 7/25\n","5/5 [==============================] - 0s 66ms/step - loss: 1.0311 - accuracy: 0.5530 - val_loss: 1.4235 - val_accuracy: 0.2667\n","Epoch 8/25\n","5/5 [==============================] - 0s 63ms/step - loss: 1.0065 - accuracy: 0.5379 - val_loss: 1.4591 - val_accuracy: 0.2667\n","Epoch 9/25\n","5/5 [==============================] - 0s 57ms/step - loss: 1.0746 - accuracy: 0.5530 - val_loss: 1.3522 - val_accuracy: 0.3333\n","Epoch 10/25\n","5/5 [==============================] - 1s 115ms/step - loss: 0.9823 - accuracy: 0.5833 - val_loss: 1.2549 - val_accuracy: 0.3333\n","Epoch 11/25\n","5/5 [==============================] - 0s 53ms/step - loss: 0.9260 - accuracy: 0.5909 - val_loss: 1.3397 - val_accuracy: 0.4667\n","Epoch 12/25\n","5/5 [==============================] - 0s 63ms/step - loss: 0.8754 - accuracy: 0.6439 - val_loss: 1.5012 - val_accuracy: 0.3333\n","Epoch 13/25\n","5/5 [==============================] - 0s 67ms/step - loss: 0.9632 - accuracy: 0.5985 - val_loss: 1.7218 - val_accuracy: 0.2000\n","Epoch 14/25\n","5/5 [==============================] - 0s 62ms/step - loss: 0.9358 - accuracy: 0.6364 - val_loss: 1.8300 - val_accuracy: 0.1333\n","Epoch 15/25\n","5/5 [==============================] - 0s 59ms/step - loss: 0.8490 - accuracy: 0.6591 - val_loss: 1.8786 - val_accuracy: 0.1333\n","Epoch 16/25\n","5/5 [==============================] - 0s 57ms/step - loss: 0.8096 - accuracy: 0.6742 - val_loss: 1.8701 - val_accuracy: 0.0667\n","Epoch 17/25\n","5/5 [==============================] - 0s 53ms/step - loss: 0.7620 - accuracy: 0.7500 - val_loss: 1.4782 - val_accuracy: 0.2000\n","Epoch 18/25\n","5/5 [==============================] - 0s 55ms/step - loss: 0.6950 - accuracy: 0.7045 - val_loss: 1.5860 - val_accuracy: 0.4667\n","Epoch 19/25\n","5/5 [==============================] - 0s 53ms/step - loss: 0.7421 - accuracy: 0.7121 - val_loss: 1.6059 - val_accuracy: 0.2667\n","Epoch 20/25\n","5/5 [==============================] - 0s 55ms/step - loss: 0.7708 - accuracy: 0.7197 - val_loss: 1.5311 - val_accuracy: 0.4000\n","Epoch 21/25\n","5/5 [==============================] - 0s 57ms/step - loss: 0.6382 - accuracy: 0.7121 - val_loss: 1.7127 - val_accuracy: 0.2667\n","Epoch 22/25\n","5/5 [==============================] - 0s 52ms/step - loss: 0.6452 - accuracy: 0.7576 - val_loss: 2.2406 - val_accuracy: 0.1333\n","Epoch 23/25\n","5/5 [==============================] - 0s 65ms/step - loss: 0.7397 - accuracy: 0.6894 - val_loss: 2.1662 - val_accuracy: 0.2000\n","Epoch 24/25\n","5/5 [==============================] - 0s 71ms/step - loss: 0.7600 - accuracy: 0.6970 - val_loss: 1.8047 - val_accuracy: 0.2667\n","Epoch 25/25\n","5/5 [==============================] - 0s 67ms/step - loss: 0.7094 - accuracy: 0.6894 - val_loss: 1.7867 - val_accuracy: 0.3333\n","Epoch 1/25\n","5/5 [==============================] - 1s 140ms/step - loss: 1.7401 - accuracy: 0.3864 - val_loss: 1.5393 - val_accuracy: 0.6000\n","Epoch 2/25\n","5/5 [==============================] - 0s 58ms/step - loss: 1.3900 - accuracy: 0.4470 - val_loss: 1.6813 - val_accuracy: 0.4667\n","Epoch 3/25\n","5/5 [==============================] - 0s 57ms/step - loss: 1.2134 - accuracy: 0.4621 - val_loss: 1.6059 - val_accuracy: 0.2667\n","Epoch 4/25\n","5/5 [==============================] - 0s 65ms/step - loss: 1.1537 - accuracy: 0.4545 - val_loss: 1.5001 - val_accuracy: 0.4000\n","Epoch 5/25\n","5/5 [==============================] - 0s 70ms/step - loss: 1.1575 - accuracy: 0.4621 - val_loss: 1.4417 - val_accuracy: 0.4667\n","Epoch 6/25\n","5/5 [==============================] - 0s 66ms/step - loss: 1.0612 - accuracy: 0.4848 - val_loss: 1.4269 - val_accuracy: 0.5333\n","Epoch 7/25\n","5/5 [==============================] - 0s 70ms/step - loss: 1.0503 - accuracy: 0.4848 - val_loss: 1.4323 - val_accuracy: 0.3333\n","Epoch 8/25\n","5/5 [==============================] - 0s 67ms/step - loss: 0.9608 - accuracy: 0.6061 - val_loss: 1.4458 - val_accuracy: 0.3333\n","Epoch 9/25\n","5/5 [==============================] - 0s 68ms/step - loss: 1.0391 - accuracy: 0.4848 - val_loss: 1.4243 - val_accuracy: 0.3333\n","Epoch 10/25\n","5/5 [==============================] - 0s 57ms/step - loss: 1.0246 - accuracy: 0.4848 - val_loss: 1.4451 - val_accuracy: 0.3333\n","Epoch 11/25\n","5/5 [==============================] - 0s 53ms/step - loss: 1.0957 - accuracy: 0.5152 - val_loss: 1.3858 - val_accuracy: 0.3333\n","Epoch 12/25\n","5/5 [==============================] - 0s 55ms/step - loss: 1.0063 - accuracy: 0.5379 - val_loss: 1.4280 - val_accuracy: 0.3333\n","Epoch 13/25\n","5/5 [==============================] - 0s 53ms/step - loss: 1.0074 - accuracy: 0.5303 - val_loss: 1.5356 - val_accuracy: 0.5333\n","Epoch 14/25\n","5/5 [==============================] - 0s 66ms/step - loss: 0.9445 - accuracy: 0.5530 - val_loss: 1.5314 - val_accuracy: 0.4667\n","Epoch 15/25\n","5/5 [==============================] - 0s 64ms/step - loss: 0.9626 - accuracy: 0.5455 - val_loss: 1.5334 - val_accuracy: 0.4000\n","Epoch 16/25\n","5/5 [==============================] - 0s 61ms/step - loss: 0.9058 - accuracy: 0.5985 - val_loss: 1.1220 - val_accuracy: 0.4667\n","Epoch 17/25\n","5/5 [==============================] - 0s 63ms/step - loss: 0.9988 - accuracy: 0.5303 - val_loss: 1.0940 - val_accuracy: 0.2667\n","Epoch 18/25\n","5/5 [==============================] - 0s 70ms/step - loss: 0.9888 - accuracy: 0.4924 - val_loss: 1.1732 - val_accuracy: 0.3333\n","Epoch 19/25\n","5/5 [==============================] - 0s 60ms/step - loss: 0.9402 - accuracy: 0.5758 - val_loss: 1.2844 - val_accuracy: 0.3333\n","Epoch 20/25\n","5/5 [==============================] - 1s 151ms/step - loss: 0.9280 - accuracy: 0.5606 - val_loss: 1.3155 - val_accuracy: 0.3333\n","Epoch 21/25\n","5/5 [==============================] - 0s 64ms/step - loss: 0.8053 - accuracy: 0.6742 - val_loss: 1.3041 - val_accuracy: 0.3333\n","Epoch 1/25\n","5/5 [==============================] - 0s 81ms/step - loss: 1.6241 - accuracy: 0.3788 - val_loss: 1.6653 - val_accuracy: 0.2000\n","Epoch 2/25\n","5/5 [==============================] - 0s 57ms/step - loss: 1.3667 - accuracy: 0.4167 - val_loss: 1.5402 - val_accuracy: 0.1333\n","Epoch 3/25\n","5/5 [==============================] - 0s 55ms/step - loss: 1.2136 - accuracy: 0.4697 - val_loss: 1.4360 - val_accuracy: 0.2000\n","Epoch 4/25\n","5/5 [==============================] - 0s 54ms/step - loss: 1.1107 - accuracy: 0.4924 - val_loss: 1.3087 - val_accuracy: 0.3333\n","Epoch 5/25\n","5/5 [==============================] - 0s 71ms/step - loss: 1.1673 - accuracy: 0.5227 - val_loss: 1.2664 - val_accuracy: 0.4000\n","Epoch 6/25\n","5/5 [==============================] - 0s 62ms/step - loss: 1.1724 - accuracy: 0.4242 - val_loss: 1.3927 - val_accuracy: 0.3333\n","Epoch 7/25\n","5/5 [==============================] - 0s 63ms/step - loss: 1.1286 - accuracy: 0.4924 - val_loss: 1.5398 - val_accuracy: 0.2000\n","Epoch 8/25\n","5/5 [==============================] - 0s 60ms/step - loss: 1.0153 - accuracy: 0.5530 - val_loss: 1.5528 - val_accuracy: 0.2000\n","Epoch 9/25\n","5/5 [==============================] - 0s 63ms/step - loss: 1.0405 - accuracy: 0.5152 - val_loss: 1.5455 - val_accuracy: 0.3333\n","Epoch 10/25\n","5/5 [==============================] - 0s 61ms/step - loss: 1.0645 - accuracy: 0.4697 - val_loss: 1.3767 - val_accuracy: 0.4000\n","Epoch 11/25\n","5/5 [==============================] - 0s 61ms/step - loss: 1.0377 - accuracy: 0.5303 - val_loss: 1.1386 - val_accuracy: 0.4000\n","Epoch 12/25\n","5/5 [==============================] - 0s 56ms/step - loss: 0.9749 - accuracy: 0.5758 - val_loss: 1.0583 - val_accuracy: 0.6000\n","Epoch 13/25\n","5/5 [==============================] - 0s 52ms/step - loss: 0.9723 - accuracy: 0.5379 - val_loss: 1.1992 - val_accuracy: 0.4667\n","Epoch 14/25\n","5/5 [==============================] - 0s 54ms/step - loss: 0.9053 - accuracy: 0.6136 - val_loss: 1.3600 - val_accuracy: 0.3333\n","Epoch 15/25\n","5/5 [==============================] - 0s 59ms/step - loss: 0.8899 - accuracy: 0.5606 - val_loss: 1.4209 - val_accuracy: 0.3333\n","Epoch 16/25\n","5/5 [==============================] - 0s 69ms/step - loss: 0.8824 - accuracy: 0.6136 - val_loss: 1.2871 - val_accuracy: 0.3333\n","Epoch 17/25\n","5/5 [==============================] - 0s 62ms/step - loss: 0.9195 - accuracy: 0.6212 - val_loss: 1.3218 - val_accuracy: 0.4667\n","Epoch 18/25\n","5/5 [==============================] - 0s 66ms/step - loss: 0.8787 - accuracy: 0.6364 - val_loss: 1.5187 - val_accuracy: 0.4667\n","Epoch 19/25\n","5/5 [==============================] - 0s 56ms/step - loss: 0.7704 - accuracy: 0.6742 - val_loss: 1.5706 - val_accuracy: 0.3333\n","Epoch 20/25\n","5/5 [==============================] - 0s 58ms/step - loss: 0.8159 - accuracy: 0.6439 - val_loss: 1.3902 - val_accuracy: 0.3333\n","Epoch 21/25\n","5/5 [==============================] - 1s 125ms/step - loss: 0.9091 - accuracy: 0.5909 - val_loss: 1.5956 - val_accuracy: 0.2667\n","Epoch 22/25\n","5/5 [==============================] - 0s 72ms/step - loss: 0.7860 - accuracy: 0.6591 - val_loss: 1.8178 - val_accuracy: 0.4000\n","Epoch 23/25\n","5/5 [==============================] - 0s 63ms/step - loss: 0.8015 - accuracy: 0.6439 - val_loss: 1.7248 - val_accuracy: 0.3333\n","Epoch 24/25\n","5/5 [==============================] - 0s 63ms/step - loss: 0.8562 - accuracy: 0.6439 - val_loss: 1.3675 - val_accuracy: 0.3333\n","Epoch 25/25\n","5/5 [==============================] - 0s 64ms/step - loss: 0.8411 - accuracy: 0.6212 - val_loss: 1.3295 - val_accuracy: 0.3333\n","Epoch 1/25\n","5/5 [==============================] - 0s 88ms/step - loss: 1.6307 - accuracy: 0.3485 - val_loss: 1.4365 - val_accuracy: 0.3333\n","Epoch 2/25\n","5/5 [==============================] - 0s 61ms/step - loss: 1.3081 - accuracy: 0.4394 - val_loss: 1.2234 - val_accuracy: 0.3333\n","Epoch 3/25\n","5/5 [==============================] - 0s 58ms/step - loss: 1.1776 - accuracy: 0.4242 - val_loss: 1.0847 - val_accuracy: 0.2667\n","Epoch 4/25\n","5/5 [==============================] - 0s 55ms/step - loss: 1.0975 - accuracy: 0.4773 - val_loss: 1.0613 - val_accuracy: 0.3333\n","Epoch 5/25\n","5/5 [==============================] - 0s 56ms/step - loss: 1.0880 - accuracy: 0.4848 - val_loss: 1.0692 - val_accuracy: 0.3333\n","Epoch 6/25\n","5/5 [==============================] - 0s 55ms/step - loss: 1.0640 - accuracy: 0.5000 - val_loss: 1.0840 - val_accuracy: 0.4667\n","Epoch 7/25\n","5/5 [==============================] - 0s 58ms/step - loss: 1.0361 - accuracy: 0.5682 - val_loss: 1.0270 - val_accuracy: 0.4667\n","Epoch 8/25\n","5/5 [==============================] - 0s 52ms/step - loss: 1.0437 - accuracy: 0.5152 - val_loss: 1.1155 - val_accuracy: 0.8000\n","Epoch 9/25\n","5/5 [==============================] - 0s 57ms/step - loss: 1.1479 - accuracy: 0.4697 - val_loss: 1.1239 - val_accuracy: 0.8000\n","Epoch 10/25\n","5/5 [==============================] - 0s 54ms/step - loss: 0.9859 - accuracy: 0.5152 - val_loss: 1.1028 - val_accuracy: 0.7333\n","Epoch 11/25\n","5/5 [==============================] - 0s 56ms/step - loss: 0.9700 - accuracy: 0.5530 - val_loss: 1.1499 - val_accuracy: 0.6000\n","Epoch 12/25\n","5/5 [==============================] - 0s 55ms/step - loss: 1.0039 - accuracy: 0.5379 - val_loss: 1.1676 - val_accuracy: 0.5333\n","Epoch 13/25\n","5/5 [==============================] - 0s 57ms/step - loss: 0.8786 - accuracy: 0.5909 - val_loss: 1.1141 - val_accuracy: 0.6000\n","Epoch 14/25\n","5/5 [==============================] - 1s 156ms/step - loss: 0.9854 - accuracy: 0.5303 - val_loss: 0.9732 - val_accuracy: 0.6000\n","Epoch 15/25\n","5/5 [==============================] - 0s 63ms/step - loss: 0.9394 - accuracy: 0.5530 - val_loss: 1.1371 - val_accuracy: 0.5333\n","Epoch 16/25\n","5/5 [==============================] - 0s 61ms/step - loss: 0.9083 - accuracy: 0.5909 - val_loss: 1.2000 - val_accuracy: 0.5333\n","Epoch 17/25\n","5/5 [==============================] - 0s 53ms/step - loss: 0.8859 - accuracy: 0.5682 - val_loss: 1.0471 - val_accuracy: 0.6000\n","Epoch 18/25\n","5/5 [==============================] - 0s 54ms/step - loss: 0.9212 - accuracy: 0.6136 - val_loss: 0.8958 - val_accuracy: 0.5333\n","Epoch 19/25\n","5/5 [==============================] - 0s 56ms/step - loss: 0.8375 - accuracy: 0.6061 - val_loss: 0.8805 - val_accuracy: 0.6000\n","Epoch 20/25\n","5/5 [==============================] - 0s 60ms/step - loss: 0.8399 - accuracy: 0.6136 - val_loss: 0.7692 - val_accuracy: 0.6667\n","Epoch 21/25\n","5/5 [==============================] - 0s 53ms/step - loss: 0.7755 - accuracy: 0.6136 - val_loss: 0.8189 - val_accuracy: 0.7333\n","Epoch 22/25\n","5/5 [==============================] - 0s 55ms/step - loss: 0.7654 - accuracy: 0.6136 - val_loss: 0.8519 - val_accuracy: 0.6667\n","Epoch 23/25\n","5/5 [==============================] - 0s 52ms/step - loss: 0.7519 - accuracy: 0.6439 - val_loss: 0.8793 - val_accuracy: 0.6000\n","Epoch 24/25\n","5/5 [==============================] - 0s 56ms/step - loss: 0.7689 - accuracy: 0.6364 - val_loss: 0.9110 - val_accuracy: 0.6000\n","Epoch 25/25\n","5/5 [==============================] - 0s 53ms/step - loss: 0.7422 - accuracy: 0.6742 - val_loss: 0.9897 - val_accuracy: 0.6667\n","Epoch 1/25\n","5/5 [==============================] - 0s 71ms/step - loss: 1.8880 - accuracy: 0.2803 - val_loss: 1.1841 - val_accuracy: 0.3333\n","Epoch 2/25\n","5/5 [==============================] - 0s 56ms/step - loss: 1.3584 - accuracy: 0.3258 - val_loss: 1.0839 - val_accuracy: 0.4667\n","Epoch 3/25\n","5/5 [==============================] - 0s 57ms/step - loss: 1.2455 - accuracy: 0.4394 - val_loss: 1.1655 - val_accuracy: 0.6667\n","Epoch 4/25\n","5/5 [==============================] - 1s 124ms/step - loss: 1.1795 - accuracy: 0.4242 - val_loss: 1.1926 - val_accuracy: 0.6667\n","Epoch 5/25\n","5/5 [==============================] - 0s 67ms/step - loss: 1.1177 - accuracy: 0.4848 - val_loss: 1.1862 - val_accuracy: 0.6000\n","Epoch 6/25\n","5/5 [==============================] - 0s 59ms/step - loss: 1.0946 - accuracy: 0.4545 - val_loss: 1.1773 - val_accuracy: 0.4000\n","Epoch 7/25\n","5/5 [==============================] - 0s 62ms/step - loss: 1.0548 - accuracy: 0.4848 - val_loss: 1.2031 - val_accuracy: 0.3333\n","Epoch 8/25\n","5/5 [==============================] - 0s 66ms/step - loss: 1.0512 - accuracy: 0.5152 - val_loss: 1.2136 - val_accuracy: 0.3333\n","Epoch 9/25\n","5/5 [==============================] - 0s 60ms/step - loss: 1.0075 - accuracy: 0.5682 - val_loss: 1.1828 - val_accuracy: 0.2667\n","Epoch 10/25\n","5/5 [==============================] - 0s 70ms/step - loss: 1.0607 - accuracy: 0.4848 - val_loss: 1.2717 - val_accuracy: 0.4667\n","Epoch 11/25\n","5/5 [==============================] - 0s 64ms/step - loss: 1.0571 - accuracy: 0.5530 - val_loss: 1.2758 - val_accuracy: 0.2667\n","Epoch 12/25\n","5/5 [==============================] - 0s 65ms/step - loss: 1.0108 - accuracy: 0.5606 - val_loss: 1.2305 - val_accuracy: 0.3333\n","Epoch 13/25\n","5/5 [==============================] - 0s 74ms/step - loss: 1.0623 - accuracy: 0.5152 - val_loss: 1.3939 - val_accuracy: 0.2667\n","Epoch 14/25\n","5/5 [==============================] - 0s 69ms/step - loss: 1.0494 - accuracy: 0.4924 - val_loss: 1.3747 - val_accuracy: 0.2667\n","Epoch 15/25\n","5/5 [==============================] - 0s 67ms/step - loss: 1.0086 - accuracy: 0.4924 - val_loss: 1.3392 - val_accuracy: 0.3333\n","Epoch 16/25\n","5/5 [==============================] - 0s 76ms/step - loss: 1.0730 - accuracy: 0.5303 - val_loss: 1.2325 - val_accuracy: 0.6000\n","Epoch 17/25\n","5/5 [==============================] - 0s 66ms/step - loss: 1.0023 - accuracy: 0.5833 - val_loss: 1.1538 - val_accuracy: 0.6000\n","Epoch 18/25\n","5/5 [==============================] - 0s 59ms/step - loss: 0.9635 - accuracy: 0.5909 - val_loss: 1.1959 - val_accuracy: 0.6000\n","Epoch 19/25\n","5/5 [==============================] - 0s 55ms/step - loss: 0.9503 - accuracy: 0.5530 - val_loss: 1.3323 - val_accuracy: 0.6000\n","Epoch 20/25\n","5/5 [==============================] - 0s 55ms/step - loss: 0.9929 - accuracy: 0.5833 - val_loss: 1.3400 - val_accuracy: 0.4667\n","Epoch 21/25\n","5/5 [==============================] - 0s 62ms/step - loss: 0.8874 - accuracy: 0.5909 - val_loss: 1.2713 - val_accuracy: 0.4667\n","Epoch 22/25\n","5/5 [==============================] - 0s 68ms/step - loss: 0.9332 - accuracy: 0.5606 - val_loss: 1.1225 - val_accuracy: 0.6000\n","Epoch 23/25\n","5/5 [==============================] - 0s 66ms/step - loss: 0.8341 - accuracy: 0.6515 - val_loss: 1.1609 - val_accuracy: 0.4667\n","Epoch 1/25\n","5/5 [==============================] - 0s 84ms/step - loss: 1.3893 - accuracy: 0.3561 - val_loss: 0.9867 - val_accuracy: 0.6000\n","Epoch 2/25\n","5/5 [==============================] - 0s 58ms/step - loss: 1.3269 - accuracy: 0.3333 - val_loss: 0.9647 - val_accuracy: 0.6000\n","Epoch 3/25\n","5/5 [==============================] - 0s 59ms/step - loss: 1.2058 - accuracy: 0.4242 - val_loss: 0.9421 - val_accuracy: 0.5333\n","Epoch 4/25\n","5/5 [==============================] - 1s 144ms/step - loss: 1.1768 - accuracy: 0.4924 - val_loss: 0.9537 - val_accuracy: 0.3333\n","Epoch 5/25\n","5/5 [==============================] - 0s 66ms/step - loss: 1.1907 - accuracy: 0.4848 - val_loss: 1.0028 - val_accuracy: 0.3333\n","Epoch 6/25\n","5/5 [==============================] - 0s 68ms/step - loss: 1.1340 - accuracy: 0.5000 - val_loss: 1.0660 - val_accuracy: 0.3333\n","Epoch 7/25\n","5/5 [==============================] - 0s 57ms/step - loss: 1.1283 - accuracy: 0.5000 - val_loss: 1.1627 - val_accuracy: 0.3333\n","Epoch 8/25\n","5/5 [==============================] - 0s 54ms/step - loss: 1.1323 - accuracy: 0.5152 - val_loss: 1.1279 - val_accuracy: 0.2000\n","Epoch 9/25\n","5/5 [==============================] - 0s 56ms/step - loss: 1.0747 - accuracy: 0.5379 - val_loss: 1.0150 - val_accuracy: 0.4000\n","Epoch 10/25\n","5/5 [==============================] - 0s 56ms/step - loss: 1.1565 - accuracy: 0.5076 - val_loss: 1.0742 - val_accuracy: 0.4667\n","Epoch 11/25\n","5/5 [==============================] - 0s 65ms/step - loss: 1.1671 - accuracy: 0.5000 - val_loss: 1.1006 - val_accuracy: 0.3333\n","Epoch 12/25\n","5/5 [==============================] - 0s 63ms/step - loss: 1.0798 - accuracy: 0.4924 - val_loss: 1.1081 - val_accuracy: 0.4667\n","Epoch 13/25\n","5/5 [==============================] - 0s 66ms/step - loss: 1.0655 - accuracy: 0.5227 - val_loss: 1.1197 - val_accuracy: 0.4000\n","Epoch 14/25\n","5/5 [==============================] - 0s 66ms/step - loss: 1.0024 - accuracy: 0.5682 - val_loss: 1.2646 - val_accuracy: 0.3333\n","Epoch 15/25\n","5/5 [==============================] - 0s 52ms/step - loss: 0.9360 - accuracy: 0.6288 - val_loss: 1.2160 - val_accuracy: 0.3333\n","Epoch 16/25\n","5/5 [==============================] - 0s 59ms/step - loss: 0.9976 - accuracy: 0.5303 - val_loss: 1.2747 - val_accuracy: 0.3333\n","Epoch 17/25\n","5/5 [==============================] - 0s 56ms/step - loss: 1.0040 - accuracy: 0.5530 - val_loss: 1.1803 - val_accuracy: 0.4667\n","Epoch 18/25\n","5/5 [==============================] - 0s 57ms/step - loss: 0.9658 - accuracy: 0.5682 - val_loss: 1.0760 - val_accuracy: 0.5333\n","Epoch 19/25\n","5/5 [==============================] - 0s 53ms/step - loss: 0.9600 - accuracy: 0.5758 - val_loss: 1.2032 - val_accuracy: 0.4000\n","Epoch 20/25\n","5/5 [==============================] - 0s 55ms/step - loss: 0.9761 - accuracy: 0.6212 - val_loss: 1.2095 - val_accuracy: 0.4000\n","Epoch 21/25\n","5/5 [==============================] - 0s 60ms/step - loss: 0.9175 - accuracy: 0.6061 - val_loss: 1.1606 - val_accuracy: 0.3333\n","[0.6666666666666666, 0.6666666666666666]\n","4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QTxMNdWd1aVt","colab":{"base_uri":"https://localhost:8080/","height":86},"executionInfo":{"status":"ok","timestamp":1610260455411,"user_tz":-210,"elapsed":438834,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"7f9b5ec0-2ff5-4927-9eb7-632b5f93660d"},"source":["\"\"\"\n","print(chromo[-1])\n","logmodel.fit(X_train[:,:,chromo[-1]],np.array(y_train),batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=(X_test[:,:,chromo[-1]], np.array(y_test)),callbacks =[earlystopping])\n","predictions = logmodel.predict_classes(X_test[:,:,chromo[-1]])\n","print(\"Accuracy score after genetic algorithm is= \"+str(accuracy_score(y_test,predictions)))\n","score2 = logmodel.evaluate((X_test[:,:,chromo[-1]]), np.array(y_test), verbose=0)\n","print('Test loss after genetic algorithm is:', score2[0])\n","print('Test accuracy after genetic algorithm is:', score2[1])\n","\n","predlstmga2=logmodel.predict_classes(X_LSAT[:,:,chromo[-1]])\n","print(predlstmga2[0])\n","\"\"\""],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nprint(chromo[-1])\\nlogmodel.fit(X_train[:,:,chromo[-1]],np.array(y_train),batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=(X_test[:,:,chromo[-1]], np.array(y_test)),callbacks =[earlystopping])\\npredictions = logmodel.predict_classes(X_test[:,:,chromo[-1]])\\nprint(\"Accuracy score after genetic algorithm is= \"+str(accuracy_score(y_test,predictions)))\\nscore2 = logmodel.evaluate((X_test[:,:,chromo[-1]]), np.array(y_test), verbose=0)\\nprint(\\'Test loss after genetic algorithm is:\\', score2[0])\\nprint(\\'Test accuracy after genetic algorithm is:\\', score2[1])\\n\\npredlstmga2=logmodel.predict_classes(X_LSAT[:,:,chromo[-1]])\\nprint(predlstmga2[0])\\n'"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"8hUmsmFRJgHA"},"source":["# **random forest **"]},{"cell_type":"code","metadata":{"id":"xI4H0h8iJfJ8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260499925,"user_tz":-210,"elapsed":483345,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"c8c13bea-ee26-44c7-835f-e8b3c1d0386a"},"source":["import pandas as pd\n","from sklearn.ensemble.forest import RandomForestClassifier\n","from sklearn.feature_selection import SelectFromModel\n","X_train=train_x[:,0,:]\n","X_test=validation_x[:,0,:]\n","y_train=np.array(train_y)\n","y_test=np.array(validation_y)\n","\n","sel = SelectFromModel(RandomForestClassifier(n_estimators = 10000))\n","sel.fit(X_train, y_train)\n","chromo2=sel.get_support()\n","#clf = RandomForestClassifier(n_estimators=10000, random_state=0, n_jobs=-1)\n","\n","\n","best_chromosome2=[i for i, x in enumerate(chromo2) if x]\n","train_x22=train_x[:,:,best_chromosome2]\n","validation_x22=validation_x[:,:,best_chromosome2]\n","print(train_x22.shape[1:])\n","print(train_x22.shape)\n","print(validation_x22.shape)\n","\n","model22 = Sequential()\n","model22.add(LSTM(128, input_shape=(train_x22.shape[1:]), return_sequences=True))\n","model22.add(Dropout(0.2))\n","model22.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n"," \n","model22.add(LSTM(128, return_sequences=True))\n","model22.add(Dropout(0.1))\n","model22.add(BatchNormalization())\n","\n","model22.add(LSTM(64))\n","model22.add(Dropout(0.2))\n","model22.add(BatchNormalization())\n"," \n","model22.add(Dense(64, activation='relu'))\n","model22.add(Dropout(0.2))\n","\n","model22.add(Dense(5, activation='softmax'))\n","\n","\n","opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n"," \n","# Compile model\n","model22.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=opt,\n","    metrics=['accuracy'])\n","#model.compile(optimizer='adam', loss='mse')\n","print(model22.summary())\n","\n","earlystopping_model22 = callbacks.EarlyStopping(monitor =\"val_loss\", mode =\"auto\", patience = 20,restore_best_weights = True) \n","history = model22.fit(train_x22, np.array(train_y),batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=(validation_x22, np.array(validation_y)),callbacks =[earlystopping_model22])\n","\n","score2 = model22.evaluate(validation_x22, np.array(validation_y), verbose=1)\n","print('Test loss:', score2[0])\n","print('Test accuracy:', score2[1])\n","pred22=model22.predict_classes(X_LSAT[:,:,best_chromosome2])\n","print(pred22[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n","  warnings.warn(message, FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["(10, 35)\n","(132, 10, 35)\n","(15, 10, 35)\n","Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_9 (LSTM)                (None, 10, 128)           83968     \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 10, 128)           0         \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 10, 128)           512       \n","_________________________________________________________________\n","lstm_10 (LSTM)               (None, 10, 128)           131584    \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 10, 128)           0         \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 10, 128)           512       \n","_________________________________________________________________\n","lstm_11 (LSTM)               (None, 64)                49408     \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 64)                256       \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 64)                4160      \n","_________________________________________________________________\n","dropout_15 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 5)                 325       \n","=================================================================\n","Total params: 270,725\n","Trainable params: 270,085\n","Non-trainable params: 640\n","_________________________________________________________________\n","None\n","Epoch 1/100\n","5/5 [==============================] - 7s 413ms/step - loss: 1.8189 - accuracy: 0.2681 - val_loss: 1.5670 - val_accuracy: 0.4667\n","Epoch 2/100\n","5/5 [==============================] - 0s 42ms/step - loss: 1.4705 - accuracy: 0.4125 - val_loss: 1.5455 - val_accuracy: 0.4667\n","Epoch 3/100\n","5/5 [==============================] - 0s 40ms/step - loss: 1.2640 - accuracy: 0.4505 - val_loss: 1.5267 - val_accuracy: 0.4667\n","Epoch 4/100\n","5/5 [==============================] - 0s 41ms/step - loss: 1.2390 - accuracy: 0.5052 - val_loss: 1.5038 - val_accuracy: 0.5333\n","Epoch 5/100\n","5/5 [==============================] - 0s 42ms/step - loss: 1.0305 - accuracy: 0.6284 - val_loss: 1.4814 - val_accuracy: 0.5333\n","Epoch 6/100\n","5/5 [==============================] - 0s 46ms/step - loss: 0.9639 - accuracy: 0.5540 - val_loss: 1.4636 - val_accuracy: 0.4667\n","Epoch 7/100\n","5/5 [==============================] - 0s 45ms/step - loss: 1.0025 - accuracy: 0.5483 - val_loss: 1.4469 - val_accuracy: 0.4667\n","Epoch 8/100\n","5/5 [==============================] - 0s 50ms/step - loss: 0.9800 - accuracy: 0.5859 - val_loss: 1.4272 - val_accuracy: 0.4667\n","Epoch 9/100\n","5/5 [==============================] - 0s 54ms/step - loss: 0.9116 - accuracy: 0.6954 - val_loss: 1.4052 - val_accuracy: 0.4667\n","Epoch 10/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.8266 - accuracy: 0.6701 - val_loss: 1.3888 - val_accuracy: 0.4000\n","Epoch 11/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.8286 - accuracy: 0.6415 - val_loss: 1.3697 - val_accuracy: 0.4667\n","Epoch 12/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.8167 - accuracy: 0.6663 - val_loss: 1.3518 - val_accuracy: 0.5333\n","Epoch 13/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.9008 - accuracy: 0.6123 - val_loss: 1.3437 - val_accuracy: 0.4667\n","Epoch 14/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.8686 - accuracy: 0.6053 - val_loss: 1.3399 - val_accuracy: 0.4000\n","Epoch 15/100\n","5/5 [==============================] - 0s 44ms/step - loss: 0.7232 - accuracy: 0.6742 - val_loss: 1.3349 - val_accuracy: 0.4000\n","Epoch 16/100\n","5/5 [==============================] - 0s 51ms/step - loss: 0.6766 - accuracy: 0.7256 - val_loss: 1.3245 - val_accuracy: 0.3333\n","Epoch 17/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.7176 - accuracy: 0.7132 - val_loss: 1.2973 - val_accuracy: 0.3333\n","Epoch 18/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.6945 - accuracy: 0.7338 - val_loss: 1.2623 - val_accuracy: 0.5333\n","Epoch 19/100\n","5/5 [==============================] - 0s 51ms/step - loss: 0.7117 - accuracy: 0.7274 - val_loss: 1.2393 - val_accuracy: 0.6000\n","Epoch 20/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.6947 - accuracy: 0.7107 - val_loss: 1.2174 - val_accuracy: 0.6000\n","Epoch 21/100\n","5/5 [==============================] - 0s 39ms/step - loss: 0.7469 - accuracy: 0.6934 - val_loss: 1.1963 - val_accuracy: 0.5333\n","Epoch 22/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.7846 - accuracy: 0.6710 - val_loss: 1.1701 - val_accuracy: 0.6667\n","Epoch 23/100\n","5/5 [==============================] - 0s 39ms/step - loss: 0.7012 - accuracy: 0.6926 - val_loss: 1.1544 - val_accuracy: 0.7333\n","Epoch 24/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.6850 - accuracy: 0.6748 - val_loss: 1.1273 - val_accuracy: 0.6667\n","Epoch 25/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.5730 - accuracy: 0.7408 - val_loss: 1.1225 - val_accuracy: 0.6667\n","Epoch 26/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.5864 - accuracy: 0.7953 - val_loss: 1.1242 - val_accuracy: 0.5333\n","Epoch 27/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.6329 - accuracy: 0.7369 - val_loss: 1.1188 - val_accuracy: 0.4000\n","Epoch 28/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.5099 - accuracy: 0.8236 - val_loss: 1.0824 - val_accuracy: 0.6667\n","Epoch 29/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.5452 - accuracy: 0.8013 - val_loss: 1.0449 - val_accuracy: 0.6000\n","Epoch 30/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.5900 - accuracy: 0.7552 - val_loss: 1.0172 - val_accuracy: 0.5333\n","Epoch 31/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.4997 - accuracy: 0.8009 - val_loss: 1.0136 - val_accuracy: 0.5333\n","Epoch 32/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.6288 - accuracy: 0.7646 - val_loss: 1.0074 - val_accuracy: 0.6667\n","Epoch 33/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.5021 - accuracy: 0.7974 - val_loss: 1.0034 - val_accuracy: 0.6667\n","Epoch 34/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.5567 - accuracy: 0.7076 - val_loss: 0.9880 - val_accuracy: 0.6667\n","Epoch 35/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.4609 - accuracy: 0.8195 - val_loss: 0.9771 - val_accuracy: 0.6000\n","Epoch 36/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.5652 - accuracy: 0.7606 - val_loss: 0.9220 - val_accuracy: 0.6000\n","Epoch 37/100\n","5/5 [==============================] - 0s 46ms/step - loss: 0.5327 - accuracy: 0.7422 - val_loss: 0.9124 - val_accuracy: 0.6000\n","Epoch 38/100\n","5/5 [==============================] - 0s 49ms/step - loss: 0.5893 - accuracy: 0.6939 - val_loss: 0.9171 - val_accuracy: 0.6000\n","Epoch 39/100\n","5/5 [==============================] - 0s 46ms/step - loss: 0.5117 - accuracy: 0.7678 - val_loss: 0.9095 - val_accuracy: 0.6667\n","Epoch 40/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.5042 - accuracy: 0.8029 - val_loss: 0.9241 - val_accuracy: 0.6667\n","Epoch 41/100\n","5/5 [==============================] - 0s 46ms/step - loss: 0.6133 - accuracy: 0.7149 - val_loss: 0.9961 - val_accuracy: 0.6667\n","Epoch 42/100\n","5/5 [==============================] - 0s 52ms/step - loss: 0.4917 - accuracy: 0.7865 - val_loss: 1.0069 - val_accuracy: 0.4667\n","Epoch 43/100\n","5/5 [==============================] - 0s 45ms/step - loss: 0.4504 - accuracy: 0.8411 - val_loss: 1.0023 - val_accuracy: 0.4667\n","Epoch 44/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.5053 - accuracy: 0.8252 - val_loss: 0.9827 - val_accuracy: 0.4667\n","Epoch 45/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.5606 - accuracy: 0.7880 - val_loss: 0.9838 - val_accuracy: 0.4667\n","Epoch 46/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.4616 - accuracy: 0.8248 - val_loss: 1.0300 - val_accuracy: 0.4667\n","Epoch 47/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.4848 - accuracy: 0.8465 - val_loss: 1.0445 - val_accuracy: 0.4667\n","Epoch 48/100\n","5/5 [==============================] - 0s 46ms/step - loss: 0.5439 - accuracy: 0.8169 - val_loss: 1.0457 - val_accuracy: 0.5333\n","Epoch 49/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.4864 - accuracy: 0.8110 - val_loss: 1.0468 - val_accuracy: 0.5333\n","Epoch 50/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.3788 - accuracy: 0.8513 - val_loss: 1.0391 - val_accuracy: 0.5333\n","Epoch 51/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.4082 - accuracy: 0.8514 - val_loss: 1.0049 - val_accuracy: 0.4667\n","Epoch 52/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.3245 - accuracy: 0.8644 - val_loss: 0.9849 - val_accuracy: 0.4667\n","Epoch 53/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.4317 - accuracy: 0.8505 - val_loss: 1.0395 - val_accuracy: 0.4667\n","Epoch 54/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.3728 - accuracy: 0.8726 - val_loss: 1.1792 - val_accuracy: 0.4000\n","Epoch 55/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.3484 - accuracy: 0.8868 - val_loss: 1.1844 - val_accuracy: 0.4000\n","Epoch 56/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.3623 - accuracy: 0.8567 - val_loss: 1.1021 - val_accuracy: 0.4000\n","Epoch 57/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.4136 - accuracy: 0.8398 - val_loss: 0.9304 - val_accuracy: 0.6000\n","Epoch 58/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.5526 - accuracy: 0.7690 - val_loss: 0.8998 - val_accuracy: 0.5333\n","Epoch 59/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.4129 - accuracy: 0.7977 - val_loss: 0.8980 - val_accuracy: 0.6000\n","Epoch 60/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.4725 - accuracy: 0.8213 - val_loss: 0.8422 - val_accuracy: 0.6000\n","Epoch 61/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.4559 - accuracy: 0.8170 - val_loss: 0.7738 - val_accuracy: 0.6667\n","Epoch 62/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.4816 - accuracy: 0.7856 - val_loss: 0.7440 - val_accuracy: 0.6667\n","Epoch 63/100\n","5/5 [==============================] - 0s 45ms/step - loss: 0.4220 - accuracy: 0.8662 - val_loss: 0.7916 - val_accuracy: 0.6000\n","Epoch 64/100\n","5/5 [==============================] - 0s 107ms/step - loss: 0.4889 - accuracy: 0.7908 - val_loss: 0.8325 - val_accuracy: 0.5333\n","Epoch 65/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.3475 - accuracy: 0.8796 - val_loss: 0.8236 - val_accuracy: 0.5333\n","Epoch 66/100\n","5/5 [==============================] - 0s 39ms/step - loss: 0.3970 - accuracy: 0.8265 - val_loss: 0.8097 - val_accuracy: 0.5333\n","Epoch 67/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.5474 - accuracy: 0.7916 - val_loss: 0.8330 - val_accuracy: 0.5333\n","Epoch 68/100\n","5/5 [==============================] - 0s 45ms/step - loss: 0.4342 - accuracy: 0.8281 - val_loss: 0.8335 - val_accuracy: 0.5333\n","Epoch 69/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.3687 - accuracy: 0.8682 - val_loss: 0.8263 - val_accuracy: 0.6000\n","Epoch 70/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.3405 - accuracy: 0.8815 - val_loss: 0.9034 - val_accuracy: 0.5333\n","Epoch 71/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.4173 - accuracy: 0.8623 - val_loss: 0.9142 - val_accuracy: 0.5333\n","Epoch 72/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.2890 - accuracy: 0.8955 - val_loss: 0.9434 - val_accuracy: 0.5333\n","Epoch 73/100\n","5/5 [==============================] - 0s 46ms/step - loss: 0.3259 - accuracy: 0.8317 - val_loss: 0.9749 - val_accuracy: 0.5333\n","Epoch 74/100\n","5/5 [==============================] - 0s 49ms/step - loss: 0.3727 - accuracy: 0.8600 - val_loss: 0.9429 - val_accuracy: 0.4667\n","Epoch 75/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.3472 - accuracy: 0.8285 - val_loss: 0.9398 - val_accuracy: 0.4667\n","Epoch 76/100\n","5/5 [==============================] - 0s 50ms/step - loss: 0.3364 - accuracy: 0.8690 - val_loss: 0.9062 - val_accuracy: 0.6000\n","Epoch 77/100\n","5/5 [==============================] - 0s 45ms/step - loss: 0.3318 - accuracy: 0.8748 - val_loss: 1.0933 - val_accuracy: 0.6000\n","Epoch 78/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.3142 - accuracy: 0.8770 - val_loss: 1.0771 - val_accuracy: 0.5333\n","Epoch 79/100\n","5/5 [==============================] - 0s 53ms/step - loss: 0.2398 - accuracy: 0.8996 - val_loss: 1.0914 - val_accuracy: 0.6000\n","Epoch 80/100\n","5/5 [==============================] - 0s 52ms/step - loss: 0.2854 - accuracy: 0.8901 - val_loss: 1.2018 - val_accuracy: 0.6667\n","Epoch 81/100\n","5/5 [==============================] - 0s 49ms/step - loss: 0.3118 - accuracy: 0.8790 - val_loss: 1.1804 - val_accuracy: 0.6000\n","Epoch 82/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.2558 - accuracy: 0.9323 - val_loss: 1.1036 - val_accuracy: 0.6000\n","1/1 [==============================] - 0s 26ms/step - loss: 0.7440 - accuracy: 0.6667\n","Test loss: 0.743979275226593\n","Test accuracy: 0.6666666865348816\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7rdwY9l2jieR","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1610260521686,"user_tz":-210,"elapsed":505102,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"ca7a7d03-b502-4287-f441-6f67acf0d27d"},"source":["from sklearn.datasets import load_boston\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import f_regression\n","import matplotlib.pyplot as plt\n","from sklearn.feature_selection import mutual_info_regression\n","# load the data\n","\n","X_train=train_x[:,0,:]\n","X_test=validation_x[:,0,:]\n","y_train=np.array(train_y)\n","y_test=np.array(validation_y)\n","\n","\n","\n","# feature selection\n","f_selector = SelectKBest(score_func=f_regression, k='all')\n","# learn relationship from training data\n","f_selector.fit(X_train, y_train)\n","# transform train input data\n","X_train_fs = f_selector.transform(X_train)\n","# transform test input data\n","X_test_fs = f_selector.transform(X_test)\n","# Plot the scores for the features\n","plt.bar([i for i in range(len(f_selector.scores_))], f_selector.scores_)\n","plt.xlabel(\"feature index\")\n","plt.ylabel(\"F-value (transformed from the correlation values)\")\n","plt.show()\n","\n","print(f_selector)\n","\n","indices = np.argsort(f_selector.scores_)[::-1]\n","features_f_regression = []\n","for i in range(40):\n","    features_f_regression.append(indices[i])\n","print(features_f_regression)\n","\n","\n","\n","\n","\n","\n","X_train=train_x[:,0,:]\n","X_test=validation_x[:,0,:]\n","y_train=np.array(train_y)\n","y_test=np.array(validation_y)\n","\n","\n","train_x22=train_x[:,:,features_f_regression]\n","validation_x22=validation_x[:,:,features_f_regression]\n","print(train_x22.shape[1:])\n","print(train_x22.shape)\n","print(validation_x22.shape)\n","\n","\n","\n","model22 = Sequential()\n","model22.add(LSTM(128, input_shape=(train_x22.shape[1:]), return_sequences=True))\n","model22.add(Dropout(0.2))\n","model22.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n"," \n","model22.add(LSTM(128, return_sequences=True))\n","model22.add(Dropout(0.1))\n","model22.add(BatchNormalization())\n","\n","model22.add(LSTM(64))\n","model22.add(Dropout(0.2))\n","model22.add(BatchNormalization())\n"," \n","model22.add(Dense(64, activation='relu'))\n","model22.add(Dropout(0.2))\n","\n","model22.add(Dense(5, activation='softmax'))\n","\n","\n","opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n"," \n","# Compile model\n","model22.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=opt,\n","    metrics=['accuracy'])\n","#model.compile(optimizer='adam', loss='mse')\n","print(model22.summary())\n","\n","earlystopping_model22 = callbacks.EarlyStopping(monitor =\"val_loss\", mode =\"auto\", patience = 20,restore_best_weights = True) \n","history = model22.fit(train_x22, np.array(train_y),batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=(validation_x22, np.array(validation_y)),callbacks =[earlystopping_model22])\n","\n","score2 = model22.evaluate(validation_x22, np.array(validation_y), verbose=1)\n","print('Test loss:', score2[0])\n","print('Test accuracy:', score2[1])\n","pred22=model22.predict_classes(X_LSAT[:,:,features_f_regression])\n","print(pred22[0])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["SelectKBest(k='all', score_func=<function f_regression at 0x7fbd97dd1b70>)\n","[78, 70, 82, 83, 28, 55, 46, 40, 33, 56, 21, 54, 39, 51, 27, 79, 10, 22, 11, 75, 30, 84, 73, 41, 24, 32, 29, 72, 36, 35, 77, 34, 58, 9, 4, 57, 59, 7, 43, 37]\n","(10, 40)\n","(132, 10, 40)\n","(15, 10, 40)\n","Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_12 (LSTM)               (None, 10, 128)           86528     \n","_________________________________________________________________\n","dropout_16 (Dropout)         (None, 10, 128)           0         \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 10, 128)           512       \n","_________________________________________________________________\n","lstm_13 (LSTM)               (None, 10, 128)           131584    \n","_________________________________________________________________\n","dropout_17 (Dropout)         (None, 10, 128)           0         \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 10, 128)           512       \n","_________________________________________________________________\n","lstm_14 (LSTM)               (None, 64)                49408     \n","_________________________________________________________________\n","dropout_18 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 64)                256       \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 64)                4160      \n","_________________________________________________________________\n","dropout_19 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 5)                 325       \n","=================================================================\n","Total params: 273,285\n","Trainable params: 272,645\n","Non-trainable params: 640\n","_________________________________________________________________\n","None\n","Epoch 1/100\n","5/5 [==============================] - 7s 398ms/step - loss: 2.0397 - accuracy: 0.2939 - val_loss: 1.5751 - val_accuracy: 0.4667\n","Epoch 2/100\n","5/5 [==============================] - 0s 42ms/step - loss: 1.3683 - accuracy: 0.4706 - val_loss: 1.5702 - val_accuracy: 0.3333\n","Epoch 3/100\n","5/5 [==============================] - 0s 42ms/step - loss: 1.2329 - accuracy: 0.4650 - val_loss: 1.5665 - val_accuracy: 0.3333\n","Epoch 4/100\n","5/5 [==============================] - 0s 45ms/step - loss: 1.2091 - accuracy: 0.4880 - val_loss: 1.5523 - val_accuracy: 0.4667\n","Epoch 5/100\n","5/5 [==============================] - 0s 46ms/step - loss: 1.1197 - accuracy: 0.5144 - val_loss: 1.5223 - val_accuracy: 0.4667\n","Epoch 6/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.9878 - accuracy: 0.6026 - val_loss: 1.4946 - val_accuracy: 0.4667\n","Epoch 7/100\n","5/5 [==============================] - 0s 50ms/step - loss: 1.1279 - accuracy: 0.4765 - val_loss: 1.4709 - val_accuracy: 0.5333\n","Epoch 8/100\n","5/5 [==============================] - 0s 42ms/step - loss: 1.0229 - accuracy: 0.5726 - val_loss: 1.4631 - val_accuracy: 0.4667\n","Epoch 9/100\n","5/5 [==============================] - 0s 40ms/step - loss: 1.0068 - accuracy: 0.5361 - val_loss: 1.4540 - val_accuracy: 0.3333\n","Epoch 10/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.9574 - accuracy: 0.5642 - val_loss: 1.4615 - val_accuracy: 0.3333\n","Epoch 11/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.9033 - accuracy: 0.5939 - val_loss: 1.4458 - val_accuracy: 0.3333\n","Epoch 12/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.8667 - accuracy: 0.6281 - val_loss: 1.4159 - val_accuracy: 0.3333\n","Epoch 13/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.8639 - accuracy: 0.6280 - val_loss: 1.4197 - val_accuracy: 0.3333\n","Epoch 14/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.8788 - accuracy: 0.6537 - val_loss: 1.4460 - val_accuracy: 0.3333\n","Epoch 15/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.7743 - accuracy: 0.6862 - val_loss: 1.4450 - val_accuracy: 0.3333\n","Epoch 16/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.8329 - accuracy: 0.6610 - val_loss: 1.4342 - val_accuracy: 0.3333\n","Epoch 17/100\n","5/5 [==============================] - 0s 39ms/step - loss: 0.7592 - accuracy: 0.7058 - val_loss: 1.4359 - val_accuracy: 0.3333\n","Epoch 18/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.7191 - accuracy: 0.7135 - val_loss: 1.4301 - val_accuracy: 0.3333\n","Epoch 19/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.7829 - accuracy: 0.6755 - val_loss: 1.4036 - val_accuracy: 0.3333\n","Epoch 20/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.8197 - accuracy: 0.6503 - val_loss: 1.3975 - val_accuracy: 0.4000\n","Epoch 21/100\n","5/5 [==============================] - 0s 45ms/step - loss: 0.8449 - accuracy: 0.6300 - val_loss: 1.3975 - val_accuracy: 0.4000\n","Epoch 22/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.7475 - accuracy: 0.6901 - val_loss: 1.3839 - val_accuracy: 0.4000\n","Epoch 23/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.6756 - accuracy: 0.7629 - val_loss: 1.3389 - val_accuracy: 0.4000\n","Epoch 24/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.6323 - accuracy: 0.7536 - val_loss: 1.3917 - val_accuracy: 0.4000\n","Epoch 25/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.6659 - accuracy: 0.7394 - val_loss: 1.4198 - val_accuracy: 0.4000\n","Epoch 26/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.6932 - accuracy: 0.7638 - val_loss: 1.4494 - val_accuracy: 0.4000\n","Epoch 27/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.6603 - accuracy: 0.6576 - val_loss: 1.4278 - val_accuracy: 0.4000\n","Epoch 28/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.6916 - accuracy: 0.6536 - val_loss: 1.3992 - val_accuracy: 0.4000\n","Epoch 29/100\n","5/5 [==============================] - 0s 49ms/step - loss: 0.6185 - accuracy: 0.7416 - val_loss: 1.3918 - val_accuracy: 0.4000\n","Epoch 30/100\n","5/5 [==============================] - 0s 50ms/step - loss: 0.6321 - accuracy: 0.7217 - val_loss: 1.3856 - val_accuracy: 0.3333\n","Epoch 31/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.6522 - accuracy: 0.7491 - val_loss: 1.3878 - val_accuracy: 0.3333\n","Epoch 32/100\n","5/5 [==============================] - 0s 45ms/step - loss: 0.6172 - accuracy: 0.7050 - val_loss: 1.3971 - val_accuracy: 0.3333\n","Epoch 33/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.5887 - accuracy: 0.7615 - val_loss: 1.3449 - val_accuracy: 0.3333\n","Epoch 34/100\n","5/5 [==============================] - 0s 44ms/step - loss: 0.7524 - accuracy: 0.7254 - val_loss: 1.2209 - val_accuracy: 0.2667\n","Epoch 35/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.6411 - accuracy: 0.7507 - val_loss: 1.1995 - val_accuracy: 0.3333\n","Epoch 36/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.7502 - accuracy: 0.7023 - val_loss: 1.3138 - val_accuracy: 0.2667\n","Epoch 37/100\n","5/5 [==============================] - 0s 40ms/step - loss: 0.5301 - accuracy: 0.7778 - val_loss: 1.4024 - val_accuracy: 0.3333\n","Epoch 38/100\n","5/5 [==============================] - 0s 44ms/step - loss: 0.7150 - accuracy: 0.7241 - val_loss: 1.4375 - val_accuracy: 0.3333\n","Epoch 39/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.5466 - accuracy: 0.8157 - val_loss: 1.4627 - val_accuracy: 0.2667\n","Epoch 40/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.5282 - accuracy: 0.8120 - val_loss: 1.4804 - val_accuracy: 0.2667\n","Epoch 41/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.5830 - accuracy: 0.7514 - val_loss: 1.4848 - val_accuracy: 0.2667\n","Epoch 42/100\n","5/5 [==============================] - 0s 46ms/step - loss: 0.4912 - accuracy: 0.8104 - val_loss: 1.5331 - val_accuracy: 0.2667\n","Epoch 43/100\n","5/5 [==============================] - 0s 51ms/step - loss: 0.5715 - accuracy: 0.7654 - val_loss: 1.5378 - val_accuracy: 0.3333\n","Epoch 44/100\n","5/5 [==============================] - 0s 47ms/step - loss: 0.4249 - accuracy: 0.8374 - val_loss: 1.4246 - val_accuracy: 0.3333\n","Epoch 45/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.4710 - accuracy: 0.8060 - val_loss: 1.5955 - val_accuracy: 0.1333\n","Epoch 46/100\n","5/5 [==============================] - 0s 46ms/step - loss: 0.5534 - accuracy: 0.8054 - val_loss: 1.7216 - val_accuracy: 0.1333\n","Epoch 47/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.5166 - accuracy: 0.8247 - val_loss: 1.7514 - val_accuracy: 0.1333\n","Epoch 48/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.4462 - accuracy: 0.7953 - val_loss: 1.7721 - val_accuracy: 0.2000\n","Epoch 49/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.4926 - accuracy: 0.8232 - val_loss: 1.7865 - val_accuracy: 0.3333\n","Epoch 50/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.5271 - accuracy: 0.7951 - val_loss: 1.7390 - val_accuracy: 0.3333\n","Epoch 51/100\n","5/5 [==============================] - 0s 44ms/step - loss: 0.4687 - accuracy: 0.8580 - val_loss: 1.7405 - val_accuracy: 0.3333\n","Epoch 52/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.4057 - accuracy: 0.8615 - val_loss: 1.7402 - val_accuracy: 0.3333\n","Epoch 53/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.5551 - accuracy: 0.7509 - val_loss: 1.7667 - val_accuracy: 0.3333\n","Epoch 54/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.4501 - accuracy: 0.8413 - val_loss: 1.7999 - val_accuracy: 0.3333\n","Epoch 55/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.4654 - accuracy: 0.7872 - val_loss: 1.7820 - val_accuracy: 0.3333\n","1/1 [==============================] - 0s 23ms/step - loss: 1.1995 - accuracy: 0.3333\n","Test loss: 1.19952392578125\n","Test accuracy: 0.3333333432674408\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rdK50YasCADZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260521688,"user_tz":-210,"elapsed":505100,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"c664c055-55bf-4db9-ef10-26c9cad75cc3"},"source":["X_train=train_x[:,0,features_f_regression]\n","X_test=validation_x[:,0,features_f_regression]\n","y_train=np.array(train_y)\n","y_test=np.array(validation_y)\n","logmodel = LogisticRegression(max_iter=10000)\n","logmodel.fit(X_train,y_train)\n","predictions = logmodel.predict(X_train)\n","pred33=logmodel.predict(X_LSAT[:,0,features_f_regression])\n","print(pred33[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FqaS7ev3moCn","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1610260536121,"user_tz":-210,"elapsed":519528,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"5ae6ebf1-ac18-41d0-971d-17a0558f4180"},"source":["# feature selection\n","f_selector = SelectKBest(score_func=mutual_info_regression, k='all')\n","# learn relationship from training data\n","f_selector.fit(X_train, y_train)\n","# transform train input data\n","X_train_fs = f_selector.transform(X_train)\n","# transform test input data\n","X_test_fs = f_selector.transform(X_test)\n","# Plot the scores for the features\n","\n","plt.bar([i for i in range(len(f_selector.scores_))], f_selector.scores_)\n","plt.xlabel(\"feature index\")\n","plt.ylabel(\"Estimated MI value\")\n","plt.show()\n","\n","indices = np.argsort(f_selector.scores_)[::-1]\n","featuresKBest = []\n","for i in range(40):\n","    featuresKBest.append(indices[i])\n","print(featuresKBest)\n","\n","X_train=train_x[:,0,:]\n","X_test=validation_x[:,0,:]\n","y_train=np.array(train_y)\n","y_test=np.array(validation_y)\n","\n","\n","train_x22=train_x[:,:,featuresKBest]\n","validation_x22=validation_x[:,:,featuresKBest]\n","print(train_x22.shape[1:])\n","print(train_x22.shape)\n","print(validation_x22.shape)\n","\n","model22 = Sequential()\n","model22.add(LSTM(128, input_shape=(train_x22.shape[1:]), return_sequences=True))\n","model22.add(Dropout(0.2))\n","model22.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n"," \n","model22.add(LSTM(128, return_sequences=True))\n","model22.add(Dropout(0.1))\n","model22.add(BatchNormalization())\n","\n","model22.add(LSTM(64))\n","model22.add(Dropout(0.2))\n","model22.add(BatchNormalization())\n"," \n","model22.add(Dense(64, activation='relu'))\n","model22.add(Dropout(0.2))\n","\n","model22.add(Dense(5, activation='softmax'))\n","\n","\n","opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)\n"," \n","# Compile model\n","model22.compile(\n","    loss='sparse_categorical_crossentropy',\n","    optimizer=opt,\n","    metrics=['accuracy'])\n","#model.compile(optimizer='adam', loss='mse')\n","print(model22.summary())\n","\n","earlystopping_model22 = callbacks.EarlyStopping(monitor =\"val_loss\", mode =\"auto\", patience = 20,restore_best_weights = True) \n","history = model22.fit(train_x22, np.array(train_y),batch_size=BATCH_SIZE,epochs=EPOCHS,validation_data=(validation_x22, np.array(validation_y)),callbacks =[earlystopping])\n","\n","score2 = model22.evaluate(validation_x22, np.array(validation_y), verbose=1)\n","print('Test loss:', score2[0])\n","print('Test accuracy:', score2[1])\n","pred22=model22.predict_classes(X_LSAT[:,:,featuresKBest])\n","print(pred22[0])"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["[10, 32, 14, 4, 3, 18, 23, 33, 20, 35, 38, 19, 6, 31, 39, 5, 37, 16, 0, 34, 12, 21, 15, 7, 11, 36, 24, 13, 17, 26, 1, 2, 22, 28, 8, 30, 25, 29, 27, 9]\n","(10, 40)\n","(132, 10, 40)\n","(15, 10, 40)\n","Model: \"sequential_5\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_15 (LSTM)               (None, 10, 128)           86528     \n","_________________________________________________________________\n","dropout_20 (Dropout)         (None, 10, 128)           0         \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 10, 128)           512       \n","_________________________________________________________________\n","lstm_16 (LSTM)               (None, 10, 128)           131584    \n","_________________________________________________________________\n","dropout_21 (Dropout)         (None, 10, 128)           0         \n","_________________________________________________________________\n","batch_normalization_16 (Batc (None, 10, 128)           512       \n","_________________________________________________________________\n","lstm_17 (LSTM)               (None, 64)                49408     \n","_________________________________________________________________\n","dropout_22 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","batch_normalization_17 (Batc (None, 64)                256       \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 64)                4160      \n","_________________________________________________________________\n","dropout_23 (Dropout)         (None, 64)                0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 5)                 325       \n","=================================================================\n","Total params: 273,285\n","Trainable params: 272,645\n","Non-trainable params: 640\n","_________________________________________________________________\n","None\n","Epoch 1/100\n","5/5 [==============================] - 7s 344ms/step - loss: 2.0691 - accuracy: 0.1733 - val_loss: 1.6144 - val_accuracy: 0.1333\n","Epoch 2/100\n","5/5 [==============================] - 0s 48ms/step - loss: 1.5285 - accuracy: 0.3617 - val_loss: 1.5943 - val_accuracy: 0.3333\n","Epoch 3/100\n","5/5 [==============================] - 0s 43ms/step - loss: 1.3175 - accuracy: 0.4414 - val_loss: 1.5778 - val_accuracy: 0.2667\n","Epoch 4/100\n","5/5 [==============================] - 0s 50ms/step - loss: 1.2470 - accuracy: 0.4951 - val_loss: 1.5609 - val_accuracy: 0.4667\n","Epoch 5/100\n","5/5 [==============================] - 0s 50ms/step - loss: 1.2395 - accuracy: 0.4813 - val_loss: 1.5465 - val_accuracy: 0.4667\n","Epoch 6/100\n","5/5 [==============================] - 0s 48ms/step - loss: 1.0350 - accuracy: 0.6499 - val_loss: 1.5431 - val_accuracy: 0.4667\n","Epoch 7/100\n","5/5 [==============================] - 0s 46ms/step - loss: 1.0233 - accuracy: 0.6109 - val_loss: 1.5480 - val_accuracy: 0.4667\n","Epoch 8/100\n","5/5 [==============================] - 0s 44ms/step - loss: 1.0381 - accuracy: 0.5848 - val_loss: 1.5484 - val_accuracy: 0.4667\n","Epoch 9/100\n","5/5 [==============================] - 0s 41ms/step - loss: 1.0358 - accuracy: 0.5885 - val_loss: 1.5503 - val_accuracy: 0.4667\n","Epoch 10/100\n","5/5 [==============================] - 0s 44ms/step - loss: 1.0135 - accuracy: 0.5984 - val_loss: 1.5498 - val_accuracy: 0.4667\n","Epoch 11/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.8831 - accuracy: 0.6683 - val_loss: 1.5412 - val_accuracy: 0.4667\n","Epoch 12/100\n","5/5 [==============================] - 0s 46ms/step - loss: 0.8520 - accuracy: 0.6646 - val_loss: 1.5344 - val_accuracy: 0.4667\n","Epoch 13/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.8068 - accuracy: 0.6632 - val_loss: 1.5224 - val_accuracy: 0.4667\n","Epoch 14/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.8381 - accuracy: 0.6552 - val_loss: 1.5056 - val_accuracy: 0.4667\n","Epoch 15/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.8573 - accuracy: 0.6254 - val_loss: 1.4933 - val_accuracy: 0.4667\n","Epoch 16/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.7748 - accuracy: 0.6786 - val_loss: 1.4952 - val_accuracy: 0.4667\n","Epoch 17/100\n","5/5 [==============================] - 0s 43ms/step - loss: 0.9230 - accuracy: 0.5645 - val_loss: 1.5079 - val_accuracy: 0.3333\n","Epoch 18/100\n","5/5 [==============================] - 0s 53ms/step - loss: 0.7733 - accuracy: 0.7096 - val_loss: 1.5158 - val_accuracy: 0.2000\n","Epoch 19/100\n","5/5 [==============================] - 0s 49ms/step - loss: 0.8322 - accuracy: 0.6695 - val_loss: 1.4862 - val_accuracy: 0.4000\n","Epoch 20/100\n","5/5 [==============================] - 0s 49ms/step - loss: 0.7795 - accuracy: 0.6810 - val_loss: 1.4474 - val_accuracy: 0.4000\n","Epoch 21/100\n","5/5 [==============================] - 0s 48ms/step - loss: 0.7508 - accuracy: 0.6838 - val_loss: 1.4243 - val_accuracy: 0.4000\n","Epoch 22/100\n","5/5 [==============================] - 0s 44ms/step - loss: 0.8225 - accuracy: 0.6518 - val_loss: 1.4222 - val_accuracy: 0.2000\n","Epoch 23/100\n","5/5 [==============================] - 0s 41ms/step - loss: 0.7162 - accuracy: 0.7064 - val_loss: 1.3976 - val_accuracy: 0.4000\n","Epoch 24/100\n","5/5 [==============================] - 0s 42ms/step - loss: 0.8084 - accuracy: 0.6547 - val_loss: 1.3698 - val_accuracy: 0.4000\n","1/1 [==============================] - 0s 22ms/step - loss: 1.5609 - accuracy: 0.4667\n","Test loss: 1.5608583688735962\n","Test accuracy: 0.46666666865348816\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y3FYOuUryaBm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610260536124,"user_tz":-210,"elapsed":519527,"user":{"displayName":"Ali Asghar Yousefian","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgTz6DfgsXlIYOLMf8kzGRWmBiVU11IbPx0V12XVg=s64","userId":"17320255365069876391"}},"outputId":"13b69cf1-a59b-4eb2-a4d9-381cb2c6d4cd"},"source":["X_train=train_x[:,0,featuresKBest]\n","X_test=validation_x[:,0,featuresKBest]\n","y_train=np.array(train_y)\n","y_test=np.array(validation_y)\n","logmodel = LogisticRegression(max_iter=10000)\n","logmodel.fit(X_train,y_train)\n","predictions = logmodel.predict(X_train)\n","pred33=logmodel.predict(X_LSAT[:,0,featuresKBest])\n","print(pred33[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6TTqyd0BO-SH"},"source":["from concurrent.futures.thread import ThreadPoolExecutor\n","from io import StringIO\n","from pathlib import Path\n","from typing import List, Union\n","from bs4 import BeautifulSoup\n","\n","import pandas as pd\n","from requests import HTTPError\n","!pip install jdatetime\n","\n","import jdatetime \n","!pip install pytse_client\n","\n","from pytse_client import config, symbols_data, tse_settings\n","from pytse_client.utils import requests_retry_session\n","from pytse_client.tse_settings import TSE_CLIENT_TYPE_DATA_URL\n","import json\n","\n","\n","import requests\n","from requests.adapters import HTTPAdapter\n","from urllib3 import Retry\n","\n","\n","def requests_retry_session(\n","        retries=10,\n","        backoff_factor=0.3,\n","        status_forcelist=(500, 502, 504, 503),\n","        session=None,\n","):\n","    session = session or requests.Session()\n","    retry = Retry(\n","        total=retries,\n","        read=retries,\n","        connect=retries,\n","        backoff_factor=backoff_factor,\n","        status_forcelist=status_forcelist,\n","    )\n","    adapter = HTTPAdapter(max_retries=retry)\n","    session.mount('http://', adapter)\n","    session.mount('https://', adapter)\n","    return session\n","\n","\n","\n","url = 'http://www.tsetmc.com/Loader.aspx?ParTree=111C1417'\n","response = requests_retry_session().get(url, timeout=10)\n","\n","response.raise_for_status()\n","\n","\n","data = StringIO(response.text)\n","\n","soup=response.text.replace('ک', 'ك').replace('ی', 'ي')\n","soup2 = BeautifulSoup(soup, 'html.parser')\n","\n","table_rows = soup2.find_all('tr')\n","\n","res = []\n","for tr in table_rows:\n","    td = tr.find_all('td')\n","    row = [tr.text.strip() for tr in td if tr.text.strip()]\n","    if row:\n","        res.append(row)\n","\n","\n","df = pd.DataFrame(res, columns=['code', 'group', 'industry group', 'tablo','namad','latin_name','namad','nam'])\n","print(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features = df[['open-close', 'low-high', 'is_quarter_end']]\n","target = df['target']\n"," \n","scaler = StandardScaler()\n","features = scaler.fit_transform(features)\n"," \n","X_train, X_valid, Y_train, Y_valid = train_test_split(\n","    features, target, test_size=0.1, random_state=2022)\n","print(X_train.shape, X_valid.shape)\n","\n","\n","#انجام تست های مختلف بر روی مدل های متفاوت \n","\n","models = [LogisticRegression(), SVC(\n","  kernel='poly', probability=True), XGBClassifier()]\n"," \n","for i in range(3):\n","  models[i].fit(X_train, Y_train)\n"," \n","  print(f'{models[i]} : ')\n","  print('Training Accuracy : ', metrics.roc_auc_score(\n","    Y_train, models[i].predict_proba(X_train)[:,1]))\n","  print('Validation Accuracy : ', metrics.roc_auc_score(\n","    Y_valid, models[i].predict_proba(X_valid)[:,1]))\n","  print()"],"metadata":{"id":"TmbjcmyOt12U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from sklearn import preprocessing\n","from ta.volatility import BollingerBands\n","from ta.trend import MACD\n","from ta.momentum import RSIIndicator\n","from keras.models import Sequential\n","from keras.layers import Conv1D,MaxPool1D,Bidirectional,LSTM,Dropout,TimeDistributed\n","from keras.layers import Dense,GlobalAveragePooling2D\n","from ta.trend import IchimokuIndicator\n","from sklearn.linear_model import LinearRegression\n","from keras.layers import Conv1D,Flatten,MaxPooling1D,Bidirectional,LSTM,Dropout,TimeDistributed,MaxPool2D\n","from keras.layers import Dense,GlobalAveragePooling2D\n","import matplotlib.pyplot as plt\n","filename = 'AAPL'\n","stock = pd.read_csv('Data/' + filename + '.csv')\n","indicator_bb = BollingerBands(close=stock[\"Close\"], n=20, ndev=2)\n","macd = MACD(close=stock[\"Close\"])\n","rsi = RSIIndicator(close=stock[\"Close\"])\n","ichi = IchimokuIndicator(high=stock[\"High\"],low=stock[\"Low\"])\n","stock['macd'] = macd.macd()\n","stock['rsi'] = rsi.rsi()\n","stock['bb_bbm'] = indicator_bb.bollinger_mavg()\n","stock['bb_bbh'] = indicator_bb.bollinger_hband()\n","stock['bb_bbl'] = indicator_bb.bollinger_lband()\n","stock['ichi_a'] = ichi.ichimoku_a()\n","stock['ichi_b'] = ichi.ichimoku_b()\n","stock['ichi_base'] = ichi.ichimoku_base_line()\n","stock['ichi_conv'] = ichi.ichimoku_conversion_line()\n","stock = stock.fillna(0)\n","print(stock)\n","#\n","scaler = preprocessing.MinMaxScaler()\n","scaled_values = scaler.fit_transform(stock.iloc[:,1:4])\n","stock.iloc[:,1:4] = scaled_values\n","\n","y_scaler = preprocessing.MinMaxScaler()\n","scaled_values = y_scaler.fit_transform(np.array(stock.iloc[:,4]).reshape(-1,1))\n","stock.iloc[:,4] = scaled_values\n","\n","scaler = preprocessing.MinMaxScaler()\n","scaled_values = scaler.fit_transform(stock.iloc[:,5:])\n","stock.iloc[:,5:] = scaled_values\n","\n","Lstock = stock.drop(['Close','Date'],1)\n","model = LinearRegression()\n","model.fit(Lstock.iloc[:,:], stock.iloc[:,4])\n","importance = model.coef_\n","for i,v in enumerate(importance):\n","\tprint('Feature: %0d, Score: %.5f' % (i,v))\n","plt.bar([Lstock.columns[x] for x in range(len(importance))], importance)\n","plt.show()\n","stock_final = stock.drop(['Date','Open','Volume','macd','bb_bbm','bb_bbh','bb_bbl','ichi_a','ichi_conv'],1)\n","\n","window_size = 50\n","week = 7\n","X = []\n","Y = []\n","print(stock_final)\n","for i in range(0 , len(stock) - window_size -1 , 1):\n","    # first = stock.iloc[i, 4]\n","    # temp = []\n","    # temp2 = []\n","    # for j in range(window_size):\n","    #     temp.append((stock_final.iloc[i + j, 4] - first) / first)\n","   # for j in range(week):\n","   #  temp2.append((stock.iloc[i +window_size, 4] - first) / first)\n","    X.append(np.array(stock_final.iloc[i:i+window_size,:]).reshape(window_size * 7,1))\n","    Y.append(np.array(stock.iloc[i+window_size,4]).reshape(1,1))\n","    # print(stock2.iloc[i:i+window_size,4])\n","    # X.append(np.array(temp).reshape(50, 1))\n","    # Y.append(np.array(temp2).reshape(1,1))\n","train_X,test_X,train_label,test_label = train_test_split(X, Y, test_size=0.1,shuffle=False)\n","len_t = len(train_X)\n","# train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_label, test_size=0.2,shuffle=True)\n","train_X = np.array(train_X)\n","test_X = np.array(test_X)\n","train_label = np.array(train_label)\n","test_label = np.array(test_label)\n","# valid_label = np.array(valid_label)\n","# valid_X = np.array(valid_X)\n","train_X = train_X.reshape(train_X.shape[0],7,50,1)\n","test_X = test_X.reshape(test_X.shape[0],7,50,1)\n","model = Sequential()\n","#add model layers\n","model.add(TimeDistributed(Conv1D(128, kernel_size=1, activation='relu', input_shape=(None,50,1))))\n","model.add(TimeDistributed(MaxPooling1D(2)))\n","model.add(TimeDistributed(Conv1D(256, kernel_size=1, activation='relu')))\n","model.add(TimeDistributed(MaxPooling1D(2)))\n","model.add(TimeDistributed(Conv1D(512, kernel_size=1, activation='relu')))\n","model.add(TimeDistributed(MaxPooling1D(2)))\n","model.add(TimeDistributed(Flatten()))\n","model.add(Bidirectional(LSTM(200,return_sequences=True)))\n","model.add(Dropout(0.25))\n","model.add(Bidirectional(LSTM(200,return_sequences=False)))\n","model.add(Dropout(0.5))\n","model.add(Dense(1, activation='linear'))\n","model.compile(optimizer='adam', loss='mse')\n","model.fit(train_X, train_label, validation_data=(test_X,test_label), epochs=200)\n","print(model.summary())\n","print(model.evaluate(test_X,test_label))\n","# model.summary()\n","# predicted  = model.predict(test_X)\n","# test_label = (test_label[:,0])\n","# predicted = np.array(predicted[:,0]).reshape(-1,1)\n","# for j in range(len_t , len_t + len(test_X)):\n","#     temp =stock.iloc[j,4]\n","#     test_label[j - len_t] = test_label[j - len_t] * temp + temp\n","#     predicted[j - len_t] = predicted[j - len_t] * temp + temp\n","# plt.plot(test_label, color = 'black', label = ' Stock Price')\n","# plt.plot(predicted, color = 'green', label = 'Predicted  Stock Price')\n","# plt.title(' Stock Price Prediction')\n","# plt.xlabel('Time')\n","# plt.ylabel(' Stock Price')\n","# plt.legend()\n","# plt.show()\n","predicted  = model.predict(test_X)\n","test_label[:,0] = y_scaler.inverse_transform(test_label[:,0])\n","predicted = np.array(predicted[:,0]).reshape(-1,1)\n","predicted = y_scaler.inverse_transform(predicted)\n","plt.plot(test_label[:,0], color = 'black', label = ' Stock Price')\n","plt.plot(predicted, color = 'green', label = 'Predicted  Stock Price')\n","plt.title(' Stock Price Prediction')\n","plt.xlabel('Time')\n","plt.ylabel(' Stock Price')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"aruX0QwbK9rn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **XGBoost for stock trend & prices prediction**(https://www.kaggle.com/code/mtszkw/xgboost-for-stock-trend-prices-prediction)\n"],"metadata":{"id":"OZgFdSkISgsT"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","import pandas as pd\n","import xgboost as xgb\n","import matplotlib.pyplot as plt\n","from xgboost import plot_importance, plot_tree\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","\n","# Time series decomposition\n","!pip install stldecompose\n","from stldecompose import decompose\n","\n","# Chart drawing\n","import plotly as py\n","import plotly.io as pio\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n","\n","# Mute sklearn warnings\n","from warnings import simplefilter\n","simplefilter(action='ignore', category=FutureWarning)\n","simplefilter(action='ignore', category=DeprecationWarning)\n","\n","# Show charts when running kernel\n","init_notebook_mode(connected=True)\n","\n","# Change default background color for all visualizations\n","layout=go.Layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(250,250,250,0.8)')\n","fig = go.Figure(layout=layout)\n","templated_fig = pio.to_templated(fig)\n","pio.templates['my_template'] = templated_fig.layout.template\n","pio.templates.default = 'my_template'"],"metadata":{"id":"NV0vfjupSgTk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#اینجا دیتا فریم نماد رو اضافه کن\n","ETF_NAME = 'CERN'\n","ETF_DIRECTORY = '/kaggle/input/price-volume-data-for-all-us-stocks-etfs/Data/Stocks/'\n","\n","df = pd.read_csv(os.path.join(ETF_DIRECTORY, ETF_NAME.lower() + '.us.txt'), sep=',')\n","\n","df['Date'] = pd.to_datetime(df['Date'])\n","df = df[(df['Date'].dt.year >= 2010)].copy()\n","df.index = range(len(df))\n","\n","df.head()"],"metadata":{"id":"2VFqqBQKS3-X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig = make_subplots(rows=2, cols=1)\n","\n","fig.add_trace(go.Ohlc(x=df.Date,\n","                      open=df.Open,\n","                      high=df.High,\n","                      low=df.Low,\n","                      close=df.Close,\n","                      name='Price'), row=1, col=1)\n","\n","fig.add_trace(go.Scatter(x=df.Date, y=df.Volume, name='Volume'), row=2, col=1)\n","\n","fig.update(layout_xaxis_rangeslider_visible=False)\n","fig.show()"],"metadata":{"id":"Hjdm3z_ES_IF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_close = df[['Date', 'Close']].copy()\n","df_close = df_close.set_index('Date')\n","df_close.head()\n","\n","decomp = decompose(df_close, period=365)\n","fig = decomp.plot()\n","fig.set_size_inches(20, 8)"],"metadata":{"id":"u0IlMFDvTaku"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['EMA_9'] = df['Close'].ewm(9).mean().shift()\n","df['SMA_5'] = df['Close'].rolling(5).mean().shift()\n","df['SMA_10'] = df['Close'].rolling(10).mean().shift()\n","df['SMA_15'] = df['Close'].rolling(15).mean().shift()\n","df['SMA_30'] = df['Close'].rolling(30).mean().shift()\n","\n","fig = go.Figure()\n","fig.add_trace(go.Scatter(x=df.Date, y=df.EMA_9, name='EMA 9'))\n","fig.add_trace(go.Scatter(x=df.Date, y=df.SMA_5, name='SMA 5'))\n","fig.add_trace(go.Scatter(x=df.Date, y=df.SMA_10, name='SMA 10'))\n","fig.add_trace(go.Scatter(x=df.Date, y=df.SMA_15, name='SMA 15'))\n","fig.add_trace(go.Scatter(x=df.Date, y=df.SMA_30, name='SMA 30'))\n","fig.add_trace(go.Scatter(x=df.Date, y=df.Close, name='Close', opacity=0.2))\n","fig.show()"],"metadata":{"id":"fpzHZP1NTbqG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def relative_strength_idx(df, n=14):\n","    close = df['Close']\n","    delta = close.diff()\n","    delta = delta[1:]\n","    pricesUp = delta.copy()\n","    pricesDown = delta.copy()\n","    pricesUp[pricesUp < 0] = 0\n","    pricesDown[pricesDown > 0] = 0\n","    rollUp = pricesUp.rolling(n).mean()\n","    rollDown = pricesDown.abs().rolling(n).mean()\n","    rs = rollUp / rollDown\n","    rsi = 100.0 - (100.0 / (1.0 + rs))\n","    return rsi\n","\n","df['RSI'] = relative_strength_idx(df).fillna(0)\n","\n","fig = go.Figure(go.Scatter(x=df.Date, y=df.RSI, name='RSI'))\n","fig.show()"],"metadata":{"id":"IatqJF66Tfjl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","EMA_12 = pd.Series(df['Close'].ewm(span=12, min_periods=12).mean())\n","EMA_26 = pd.Series(df['Close'].ewm(span=26, min_periods=26).mean())\n","df['MACD'] = pd.Series(EMA_12 - EMA_26)\n","df['MACD_signal'] = pd.Series(df.MACD.ewm(span=9, min_periods=9).mean())\n","\n","fig = make_subplots(rows=2, cols=1)\n","fig.add_trace(go.Scatter(x=df.Date, y=df.Close, name='Close'), row=1, col=1)\n","fig.add_trace(go.Scatter(x=df.Date, y=EMA_12, name='EMA 12'), row=1, col=1)\n","fig.add_trace(go.Scatter(x=df.Date, y=EMA_26, name='EMA 26'), row=1, col=1)\n","fig.add_trace(go.Scatter(x=df.Date, y=df['MACD'], name='MACD'), row=2, col=1)\n","fig.add_trace(go.Scatter(x=df.Date, y=df['MACD_signal'], name='Signal line'), row=2, col=1)\n","fig.show()\n","\n"],"metadata":{"id":"ayqnpu28TujN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['Close'] = df['Close'].shift(-1)"],"metadata":{"id":"7v1Yq3WZTzcv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = df.iloc[33:] # Because of moving averages and MACD line\n","df = df[:-1]      # Because of shifting close price\n","\n","df.index = range(len(df))"],"metadata":{"id":"pzrPkHLuT1mW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_size  = 0.15\n","valid_size = 0.15\n","\n","test_split_idx  = int(df.shape[0] * (1-test_size))\n","valid_split_idx = int(df.shape[0] * (1-(valid_size+test_size)))\n","\n","train_df  = df.loc[:valid_split_idx].copy()\n","valid_df  = df.loc[valid_split_idx+1:test_split_idx].copy()\n","test_df   = df.loc[test_split_idx+1:].copy()\n","\n","fig = go.Figure()\n","fig.add_trace(go.Scatter(x=train_df.Date, y=train_df.Close, name='Training'))\n","fig.add_trace(go.Scatter(x=valid_df.Date, y=valid_df.Close, name='Validation'))\n","fig.add_trace(go.Scatter(x=test_df.Date,  y=test_df.Close,  name='Test'))\n","fig.show()"],"metadata":{"id":"vT_QpQ59T5LY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drop_cols = ['Date', 'Volume', 'Open', 'Low', 'High', 'OpenInt']\n","\n","train_df = train_df.drop(drop_cols, 1)\n","valid_df = valid_df.drop(drop_cols, 1)\n","test_df  = test_df.drop(drop_cols, 1)"],"metadata":{"id":"D8NX2sWET73W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train = train_df['Close'].copy()\n","X_train = train_df.drop(['Close'], 1)\n","\n","y_valid = valid_df['Close'].copy()\n","X_valid = valid_df.drop(['Close'], 1)\n","\n","y_test  = test_df['Close'].copy()\n","X_test  = test_df.drop(['Close'], 1)\n","\n","X_train.info()"],"metadata":{"id":"tjVXyiSnUQ9d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","\n","parameters = {\n","    'n_estimators': [100, 200, 300, 400],\n","    'learning_rate': [0.001, 0.005, 0.01, 0.05],\n","    'max_depth': [8, 10, 12, 15],\n","    'gamma': [0.001, 0.005, 0.01, 0.02],\n","    'random_state': [42]\n","}\n","\n","eval_set = [(X_train, y_train), (X_valid, y_valid)]\n","model = xgb.XGBRegressor(eval_set=eval_set, objective='reg:squarederror', verbose=False)\n","clf = GridSearchCV(model, parameters)\n","\n","clf.fit(X_train, y_train)\n","\n","print(f'Best params: {clf.best_params_}')\n","print(f'Best validation score = {clf.best_score_}')"],"metadata":{"id":"0IWq6FilUWc4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = xgb.XGBRegressor(**clf.best_params_, objective='reg:squarederror')\n","model.fit(X_train, y_train, eval_set=eval_set, verbose=False)"],"metadata":{"id":"za2djdwnUeNu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_importance(model);"],"metadata":{"id":"PGrug6pUUkY9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = model.predict(X_test)\n","print(f'y_true = {np.array(y_test)[:5]}')\n","print(f'y_pred = {y_pred[:5]}')"],"metadata":{"id":"-Fas7sDMUnlt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'mean_squared_error = {mean_squared_error(y_test, y_pred)}')"],"metadata":{"id":"YoP4keoIU1tt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_prices = df.loc[test_split_idx+1:].copy()\n","predicted_prices['Close'] = y_pred\n","\n","fig = make_subplots(rows=2, cols=1)\n","fig.add_trace(go.Scatter(x=df.Date, y=df.Close,\n","                         name='Truth',\n","                         marker_color='LightSkyBlue'), row=1, col=1)\n","\n","fig.add_trace(go.Scatter(x=predicted_prices.Date,\n","                         y=predicted_prices.Close,\n","                         name='Prediction',\n","                         marker_color='MediumPurple'), row=1, col=1)\n","\n","fig.add_trace(go.Scatter(x=predicted_prices.Date,\n","                         y=y_test,\n","                         name='Truth',\n","                         marker_color='LightSkyBlue',\n","                         showlegend=False), row=2, col=1)\n","\n","fig.add_trace(go.Scatter(x=predicted_prices.Date,\n","                         y=y_pred,\n","                         name='Prediction',\n","                         marker_color='MediumPurple',\n","                         showlegend=False), row=2, col=1)\n","\n","fig.show()"],"metadata":{"id":"KHyO0uinacsG"},"execution_count":null,"outputs":[]}]}